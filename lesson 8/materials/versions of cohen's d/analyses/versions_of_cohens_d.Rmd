---
title: "Not-so-standardized effect sizes"
subtitle: "Versions of Cohen's *d* for dependent data"
author: "Ian Hussey & Jamie Cummins"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    code_folding: hide
    highlight: haddock
    theme: flatly
    toc: yes
    toc_float: yes
---

# TODO

- add explanatory notes about which metrics have more and less desirable properties, what desirable properties are, and which metrics should agree etc.
- determine what the remaining metrics are doing under the hood, ie the ones labelled '???'
- obtain code for cohens_dav from {esci} for dependent data? It used to exist.

# Sources

My interest in this dates back to a blog post by Westfall (2016), originally found at http://jakewestfall.org/blog/index.php/2016/03/25/five-different-cohens-d-statistics-for-within-subject-designs/ but the website is now down. A copy is maintained at https://imaging.mrc-cbu.cam.ac.uk/statswiki/FAQ/tdunpaired as of 2024. The easystats R package {effectsize} was recently updated to include implementations of many different within-subjects Cohen's *d* variants (see [here](https://easystats.github.io/effectsize/reference/repeated_measures_d.html)), which make me think to revisit this issue to see what other variants and implementations exist.

Note that I found what appears to be an error in Jake's code that I don't see documented elsewhere: Jake specified that $d_t$ could be calculated using `d_t = t_stat * sqrt(2/n)`, where t_stat is the t statistic from a Student's t test. This math agrees with Lakens (2013) equation 2, i.e., `d_t = t_stat * sqrt(1/n1 + 1/n2)`. However, this applies only to an independent t-test - Jake's original blog misapplies the formula for an indepenent t-test to a dependent. The correct formula for a dependent t-test seems to be `d_t = t_stat / sqrt(n)`. 

```{r include=FALSE}

knitr::opts_chunk$set(message = FALSE, 
                      warning = FALSE)

options(scipen=999)

```

# Dependencies 

N.B.: to ensure full computational reproducibility, R version 4.3.3 should be used. 

```{r}

library(groundhog)

groundhog_day = "2024-04-07"

packages = c("effectsize","faux","janitor",
             "rstatix", "effsize",
             "psych", "MBESS", "lsr",
             "metafor", "esc", "esci",
             "dplyr", "tidyr", "tibble",
             "forcats", "ggplot2", "stringr")

groundhog.library(packages, groundhog_day)

```

# Functions

```{r}

cohens_d_s_metafor <- function(data){
  # nb always applies hedges correction
  require(dplyr)
  require(tibble)
  require(metafor)
  
  summaries <- data |>
    group_by(timepoint) |>
    summarize(mean = mean(score),
              sd = sd(score),
              n = n()) |>
    pivot_wider(names_from = "timepoint",
                values_from = c("mean", "sd", "n"))
  
  fit <- escalc(measure = "SMD", 
                m1i = mean_post, 
                sd1i = sd_post, 
                n1i = n_post,
                m2i = mean_pre, 
                sd2i = sd_pre, 
                n2i = n_pre, 
                data = summaries, 
                append = FALSE)
  
  res <- 
    tibble(estimate = fit$yi,
           ci_lower = fit$yi - sqrt(fit$vi)*1.96,
           ci_upper = fit$yi + sqrt(fit$vi)*1.96)
  return(res)
}


cohens_d_s_esc <- function(data, hedges_correction = TRUE){
  require(dplyr)
  require(tibble)
  require(esc)
  
  summaries <- data |>
    group_by(timepoint) |>
    summarize(mean = mean(score),
              sd = sd(score),
              n = n())
  
  fit <- esc::esc_mean_sd(grp1m  = summaries$mean[summaries$timepoint == "post"],
                          grp1sd = summaries$sd[summaries$timepoint == "post"],
                          grp1n  = summaries$n[summaries$timepoint == "post"],
                          grp2m  = summaries$mean[summaries$timepoint == "pre"],
                          grp2sd = summaries$sd[summaries$timepoint == "pre"],
                          grp2n  = summaries$n[summaries$timepoint == "pre"],
                          es.type = ifelse(hedges_correction, "g", "d"))
  
  res <- 
    tibble(estimate = fit$es,
           ci_lower = fit$ci.lo,
           ci_upper = fit$ci.hi)
  
  return(res)
}


cohens_d_z_esc <- function(data, hedges_correction = TRUE){
  require(dplyr)
  require(tibble)
  require(esc)
  
  summaries <- data |>
    group_by(timepoint) |>
    summarize(mean = mean(score),
              sd = sd(score),
              n = n())
  
  r <- data |>
    pivot_wider(names_from = "timepoint",
                values_from = "score") |>
    dplyr::select(-id) |>
    cor_test()
  
  fit <- esc::esc_mean_sd(grp1m  = summaries$mean[summaries$timepoint == "post"],
                          grp1sd = summaries$sd[summaries$timepoint == "post"],
                          grp1n  = summaries$n[summaries$timepoint == "post"],
                          grp2m  = summaries$mean[summaries$timepoint == "pre"],
                          grp2sd = summaries$sd[summaries$timepoint == "pre"],
                          grp2n  = summaries$n[summaries$timepoint == "pre"],
                          r = r$cor,
                          es.type = ifelse(hedges_correction, "g", "d"))
  
  res <- 
    tibble(estimate = fit$es,
           ci_lower = fit$ci.lo,
           ci_upper = fit$ci.hi)
  
  return(res)
}


cohens_d_s_rstatix <- function(data, hedges_correction = TRUE){
  require(dplyr)
  require(tibble)
  require(rstatix)
  
  fit <- rstatix::cohens_d(formula = score ~ timepoint,
                           data = data,
                           comparisons = list(c("pre", "post")),
                           ref.group = "post",
                           paired = FALSE,
                           hedges.correction = hedges_correction,
                           ci = TRUE,
                           ci.type = "bca",
                           nboot = 2000)
  
  res <- 
    tibble(estimate = fit$effsize,
           ci_lower = fit$conf.low,
           ci_upper = fit$conf.high)
  
  return(res)
}


cohens_d_z_rstatix <- function(data, hedges_correction = TRUE){
  require(dplyr)
  require(tibble)
  require(rstatix)
  
  fit <- rstatix::cohens_d(formula = score ~ timepoint,
                           data = data,
                           comparisons = list(c("pre", "post")),
                           ref.group = "post",
                           paired = TRUE,
                           hedges.correction = hedges_correction,
                           ci = TRUE,
                           ci.type = "bca",
                           nboot = 2000)
  
  res <- 
    tibble(estimate = fit$effsize,
           ci_lower = fit$conf.low,
           ci_upper = fit$conf.high)
  
  return(res)
}


# esci used to have a within subjects d in 2020 but now doesn't? and its not in the git history
cohens_d_s_esci <- function(data, hedges_correction = TRUE){
  require(dplyr)
  require(tibble)
  require(esci)
  
  summaries <- data |>
    group_by(timepoint) |>
    summarize(mean = mean(score),
              sd = sd(score),
              n = n())
  
  fit <- esci::CI_smd_ind_contrast(means = summaries$mean,
                                   sds = summaries$sd,
                                   ns = summaries$n,
                                   contrast = c(+1, -1),
                                   conf_level = 0.95,
                                   assume_equal_variance = FALSE,
                                   correct_bias = hedges_correction)
  
  res <- 
    tibble(estimate = fit$effect_size,
           ci_lower = fit$LL,
           ci_upper = fit$UL)
  
  return(res)
}


cohens_d_s_effsize <- function(data, hedges_correction = TRUE){
  require(dplyr)
  require(tibble)
  require(effsize)
  
  fit <- effsize::cohen.d(score ~ timepoint, 
                          paired = FALSE,
                          pooled = TRUE,
                          hedges.correction = hedges_correction,
                          data = data)
  
  res <- 
    tibble(estimate = fit$estimate,
           ci_lower = fit$conf.int[1],
           ci_upper = fit$conf.int[2])
  
  return(res)
}


cohens_d_dep_effsize <- function(data, hedges_correction = TRUE){
  require(dplyr)
  require(tibble)
  require(effsize)
  
  fit <- effsize::cohen.d(score ~ timepoint | Subject(id), 
                          paired = TRUE,
                          pooled = TRUE,
                          hedges.correction = hedges_correction,
                          data = data)
  
  res <- 
    tibble(estimate = fit$estimate,
           ci_lower = fit$conf.int[1],
           ci_upper = fit$conf.int[2])
  
  return(res)
}



cohens_d_s_psych <- function(data, hedges_correction = TRUE){
  require(dplyr)
  require(tibble)
  require(psych)
  
  fit <- psych::cohen.d(score ~ timepoint,
                        data = data) 
  
  res <- 
    tibble(estimate = ifelse(hedges_correction, fit$hedges.g[2]*-1, fit$cohen.d[2]*-1),
           ci_lower = ifelse(hedges_correction, min(fit$hedges.g*-1), min(fit$cohen.d*-1)),
           ci_upper = ifelse(hedges_correction, max(fit$hedges.g*-1), max(fit$cohen.d*-1)))
  
  return(res)
}



cohens_d_s_mbess <- function(data, hedges_correction = TRUE){
  require(dplyr)
  require(MBESS)
  
  d <- MBESS::smd(Group.1 = data |> filter(timepoint == "post") |> pull(score), 
                  Group.2 = data |> filter(timepoint == "pre") |> pull(score),
                  Unbiased = hedges_correction)
  
  t <- t.test(score ~ timepoint, data = data)$statistic
  
  cis <- ci.smd(ncp = t,
                #smd = d, 
                n.1 = data |> filter(timepoint == "post") |> pull(score) |> length(), 
                n.2 = data |> filter(timepoint == "pre") |> pull(score) |> length())
  
  res <- 
    data.frame(estimate = cis$smd,
               ci_lower = cis$Lower.Conf.Limit.smd,
               ci_upper = cis$Upper.Conf.Limit.smd) 
  
  return(res)
}


cohens_d_s_lsr <- function(data){
  require(dplyr)
  require(tibble)
  require(lsr)
  
  # note that lsr::cohenD returns the absolute value of cohen's d, ie always positive values. fix this here to bring it in line with other packages' functions.
  mean_pre <- data |> dplyr::filter(timepoint == "pre") |> summarize(mean = mean(score))
  mean_post <- data |> dplyr::filter(timepoint == "post") |> summarize(mean = mean(score))
  
  d <- lsr::cohensD(score ~ timepoint,
                    data = data) 
  
  res <- 
    tibble(estimate = as.numeric(ifelse(mean_pre < mean_post, d, d * -1)),
           ci_lower = NA,
           ci_upper = NA) 
  
  return(res)
}


cohens_d_dep_lsr <- function(data){
  require(dplyr)
  require(tibble)
  require(lsr)
  
  # note that lsr::cohenD returns the absolute value of cohen's d, ie always positive values. fix this here to bring it in line with other packages' functions.
  mean_pre <- data |> dplyr::filter(timepoint == "pre") |> summarize(mean = mean(score))
  mean_post <- data |> dplyr::filter(timepoint == "post") |> summarize(mean = mean(score))
  
  d <- lsr::cohensD(data |> dplyr::filter(timepoint == "pre") |> pull(score),
                    data |> dplyr::filter(timepoint == "post") |> pull(score),
                    method = "paired") 
  
  res <- 
    tibble(estimate = as.numeric(ifelse(mean_pre < mean_post, d, d * -1)),
           ci_lower = NA,
           ci_upper = NA) 
  
  return(res)
}


# assumes that 'data' contains columns named score (numeric) and timepoint (factor with two levels, pre and post, where positive cohen's d means higher scores at post)
# assumes a two sided Student's t test with alpha = .05
# by default, assumes correlation between timepoints is 0. larger values will narrow the CIs but leave the estimate unchanged. so, default result is the worst case precision.
d_t_dependent <- function(data, hedges_correction = TRUE, r = 0) { # assumes a correlation of 0 for simplicity
  require(dplyr)
  
  fit <- t.test(data$score[data$timepoint == "post"],
                data$score[data$timepoint == "pre"], 
                paired = TRUE)
  
  res <- 
    data.frame(t_stat = fit$statistic["t"],
               df = fit$parameter["df"],
               r = r) |>
    mutate(n = df + 1, # for dependent t test, n = df + 1
           dt_estimate = t_stat / sqrt(n), # for dependent t test, d_t = t / sqrt(n)
           dt_estimate = ifelse(hedges_correction, 
                                dt_estimate * (1 - (3 / (4 * n - 9))),
                                dt_estimate),
           dt_se = sqrt((2 * (1 - r)) / n + (dt_estimate ^ 2) / (2 * n)), # default assumes a correlation of 0
           ci_lower = dt_estimate - (1.96 * dt_se),
           ci_upper = dt_estimate + (1.96 * dt_se),
           hedges_correction = hedges_correction) |>
    dplyr::select(hedges_correction, estimate = dt_estimate, ci_lower, ci_upper)
  
  return(res)
}


# cohen's d from a Student's t test (two sided, alpha = .05)
# if a Welches' t test, the conversion of df to N is imprecise, affecting the CIs.
# assumes that 'data' contains columns named score (numeric) and timepoint (factor with two levels)
d_t_independent <- function(data, hedges_correction = TRUE){
  require(dplyr)
  
  fit <- t.test(score ~ timepoint, 
                data = data,
                paired = FALSE, 
                var.equal = TRUE)
  
  res <- 
    data.frame(t_stat = fit$statistic["t"],
               df = fit$parameter["df"]) |>
    mutate(n1 = data |> filter(timepoint == "post") |> nrow(),
           n2 = data |> filter(timepoint == "pre") |> nrow(),
           dt_estimate = t_stat * sqrt(1/n1 + 1/n2), # d = t * sqrt(1/n1 + 1/n2) - from lakens 2013 equation 2
           dt_estimate = ifelse(hedges_correction, 
                                dt_estimate * (1 - (3 / (4 * n - 9))),
                                dt_estimate),
           dt_se = sqrt((n1 + n2) / (n1 * n2) + (dt_estimate^2) / (2 * (n1 + n2 - 2))),
           ci_lower = dt_estimate - (1.96 * dt_se),
           ci_upper = dt_estimate + (1.96 * dt_se),
           hedges_correction = hedges_correction) |>
    dplyr::select(hedges_correction, estimate = dt_estimate, ci_lower, ci_upper)
  
  return(res)
}


multiple_cohens_ds_for_dependent_data <- function(data, hedges_correction = TRUE){
  
  # Check if 'data' is a dataframe or tibble
  if (!is.data.frame(data) && !is_tibble(data)) {
    stop("The 'data' argument must be a dataframe or tibble.")
  }
  
  # Check for 'score' column and its type
  if (!"score" %in% names(data) || !is.numeric(data$score)) {
    stop("The 'data' must contain a numeric column named 'score'.")
  }
  
  # Check for 'timepoint' column, its type, and number of levels
  if (!"timepoint" %in% names(data)) {
    stop("The 'data' must contain a column named 'timepoint'.")
  }
  if (!is.factor(data$timepoint) && !is.character(data$timepoint)) {
    stop("The 'timepoint' column must be of type factor or character.")
  }
  
  # some pivots below assume only these columns are present
  data <- data |>
    select(id, timepoint, score)
  
  # Convert 'timepoint' to factor if it's not already
  data$timepoint <- as.factor(data$timepoint)
  
  # Check that 'timepoint' has exactly two levels
  if (nlevels(data$timepoint) != 2) {
    stop("The 'timepoint' column must have exactly two levels.")
  }
  
  results <- 
    bind_rows(
      effectsize::cohens_d(score ~ timepoint, data = data, pooled_sd = TRUE, adjust = hedges_correction) |> 
        as_tibble() |> 
        mutate(type = "d_s",
               implementation = "{effectsize}",
               hedges_correction = hedges_correction) |>
        dplyr::select(implementation, type, hedges_correction, estimate = Hedges_g, ci_lower = CI_low, ci_upper = CI_high),
      
      cohens_d_s_psych(data = data, hedges_correction = hedges_correction) |> 
        as_tibble() |> 
        mutate(type = "d_s",
               implementation = "{psych}",
               hedges_correction = hedges_correction) |>
        dplyr::select(implementation, type, hedges_correction, estimate, ci_lower, ci_upper),
      
      cohens_d_s_mbess(data = data, hedges_correction = hedges_correction) |> 
        mutate(type = "d_s",
               implementation = "{MBESS}",
               hedges_correction = hedges_correction) |>
        dplyr::select(implementation, type, hedges_correction, estimate, ci_lower, ci_upper),
      
      cohens_d_s_effsize(data = data, hedges_correction = hedges_correction) |> 
        mutate(type = "d_s",
               implementation = "{effsize}",
               hedges_correction = hedges_correction) |>
        dplyr::select(implementation, type, hedges_correction, estimate, ci_lower, ci_upper),
      
      cohens_d_s_rstatix(data = data, hedges_correction = hedges_correction) |> 
        mutate(type = "d_s",
               implementation = "{rstatix}",
               hedges_correction = hedges_correction) |>
        dplyr::select(implementation, type, hedges_correction, estimate, ci_lower, ci_upper),
      
      cohens_d_s_metafor(data = data) |> 
        mutate(type = "d_s",
               implementation = "{metafor}",
               hedges_correction = TRUE) |> # nb always applies hedges correction
        dplyr::select(implementation, type, hedges_correction, estimate, ci_lower, ci_upper),
      
      cohens_d_z_rstatix(data = data, hedges_correction = hedges_correction) |> 
        mutate(type = "d_z",
               implementation = "{rstatix}",
               hedges_correction = hedges_correction) |>
        dplyr::select(implementation, type, hedges_correction, estimate, ci_lower, ci_upper),
      
      cohens_d_s_esc(data = data, hedges_correction = hedges_correction) |> 
        mutate(type = "d_s",
               implementation = "{esc}",
               hedges_correction = hedges_correction) |>
        dplyr::select(implementation, type, hedges_correction, estimate, ci_lower, ci_upper),
      
      cohens_d_z_esc(data = data, hedges_correction = hedges_correction) |> 
        mutate(type = "d_??? (dep)",
               implementation = "{esc}",
               hedges_correction = hedges_correction) |>
        dplyr::select(implementation, type, hedges_correction, estimate, ci_lower, ci_upper),
      
      cohens_d_s_esci(data = data, hedges_correction = hedges_correction) |> 
        mutate(type = "d_??? (indep)",
               implementation = "{esci}",
               hedges_correction = hedges_correction) |>
        dplyr::select(implementation, type, hedges_correction, estimate, ci_lower, ci_upper),
      
      cohens_d_dep_effsize(data = data, hedges_correction = hedges_correction) |> 
        mutate(type = "d_??? (dep)",
               implementation = "{effsize}",
               hedges_correction = hedges_correction) |>
        dplyr::select(implementation, type, hedges_correction, estimate, ci_lower, ci_upper),
      
      cohens_d_s_lsr(data = data) |> 
        mutate(type = "d_s",
               implementation = "{lsr}",
               hedges_correction = FALSE) |> # lsr doesn't have an option for hedges corrections
        dplyr::select(implementation, type, hedges_correction, estimate, ci_lower, ci_upper),
      
      cohens_d_dep_lsr(data = data) |> 
        mutate(type = "d_z",
               implementation = "{lsr}",
               hedges_correction = FALSE) |> # lsr doesn't have an option for hedges corrections
        dplyr::select(implementation, type, hedges_correction, estimate, ci_lower, ci_upper),
      
      # this provides nearly identical results to d_s under most conditions
      # effectsize::cohens_d(score ~ timepoint, data = data, pooled_sd = FALSE, adjust = hedges_correction) |>
      #   as_tibble() |>
      #   mutate(type = "d_s_nonpooled",
      #          implementation = "{effectsize}",
      #          hedges_correction = hedges_correction) |>
      #   dplyr::select(implementation, type, hedges_correction, estimate = Hedges_g, ci_lower = CI_low, ci_upper = CI_high),
      
      effectsize::repeated_measures_d(score ~ timepoint | id, data = data, method = "d", adjust = hedges_correction) |> 
        as_tibble() |> 
        mutate(type = "d_s_withinCIs",
               implementation = "{effectsize}",
               hedges_correction = hedges_correction) |>
        dplyr::select(implementation, type, hedges_correction, estimate = Cohens_d, ci_lower = CI_low, ci_upper = CI_high),
      
      effectsize::repeated_measures_d(score ~ timepoint | id, data = data, method = "rm", adjust = hedges_correction) |> 
        as_tibble() |> 
        mutate(type = "d_rm",
               implementation = "{effectsize}",
               hedges_correction = hedges_correction) |>
        dplyr::select(implementation, type, hedges_correction, estimate = d_rm, ci_lower = CI_low, ci_upper = CI_high),
      
      effectsize::repeated_measures_d(score ~ timepoint | id, data = data, method = "av", adjust = hedges_correction) |> 
        as_tibble() |> 
        mutate(type = "d_av",
               implementation = "{effectsize}",
               hedges_correction = hedges_correction) |>
        dplyr::select(implementation, type, hedges_correction, estimate = d_av, ci_lower = CI_low, ci_upper = CI_high),
      
      effectsize::repeated_measures_d(score ~ timepoint | id, data = data, method = "b", adjust = hedges_correction) |> 
        as_tibble() |> 
        mutate(type = "d_b",
               implementation = "{effectsize}",
               hedges_correction = hedges_correction) |>
        dplyr::select(implementation, type, hedges_correction, estimate = Beckers_d, ci_lower = CI_low, ci_upper = CI_high),
      
      # use timepoint post's SD rather than pre. 
      # this is useful to include as not all comparisons are pre-post, some are the same participants rating stimulus X and Y, and either could be the reference
      data |>
        mutate(timepoint = fct_relevel(timepoint, "pre", "post")) |>
        effectsize::repeated_measures_d(score ~ timepoint | id, data = _, method = "b", adjust = hedges_correction) |> 
        as_tibble() |> 
        mutate(type = "d_b (alt)",
               implementation = "{effectsize}",
               hedges_correction = hedges_correction,
               estimate = Beckers_d * -1,
               ci_lower = CI_high * -1,
               ci_upper = CI_low * -1) |>
        dplyr::select(implementation, type, hedges_correction, estimate, ci_lower, ci_upper),
      
      effectsize::repeated_measures_d(score ~ timepoint | id, data = data, method = "z", adjust = hedges_correction) |> 
        as_tibble() |> 
        mutate(type = "d_z",
               implementation = "{effectsize}",
               hedges_correction = hedges_correction) |>
        dplyr::select(implementation, type, hedges_correction, estimate = d_z, ci_lower = CI_low, ci_upper = CI_high),
      
      # this provides the same estimate as d_s
      d_t_independent(data = data, hedges_correction = hedges_correction) |>
        as_tibble() |>
        mutate(type = "d_t (independent)",
               implementation = "[custom]",
               hedges_correction = hedges_correction) |>
        dplyr::select(implementation, type, hedges_correction, estimate, ci_lower, ci_upper),
      
      # this provides the same estimate as d_z with slightly wider CIs
      d_t_dependent(data = data, hedges_correction = hedges_correction) |>
        as_tibble() |>
        mutate(type = "d_t (dependent, r = 0)",
               implementation = "[custom]",
               hedges_correction = hedges_correction) |>
        dplyr::select(implementation, type, hedges_correction, estimate, ci_lower, ci_upper)
    )
  return(results)
}

```

# Simulate data

## Sim 1

```{r}

set.seed(42) 

# parameters
n <- 1000 # number of participants
mean_pre <- 0 # mean for pre-test scores
mean_post <- 0.2 # mean for pre-test scores
sd_pre <- 1 # SD pre-test scores
sd_post <- 1 # SD pre-test scores
r_pre_post <- 0.8 # correlation between pre and post

# simulate data 
data_simulated_sim_1 <- 
  faux::rnorm_multi(n, 
                    mu = c(pre = mean_pre, post = mean_post), 
                    sd = c(sd_pre, sd_post), 
                    r = matrix(c(1,          r_pre_post, 
                                 r_pre_post,         1), 
                               ncol = 2)) |>
  rownames_to_column(var = "id") |>
  pivot_longer(cols = -id,
               names_to = "timepoint",
               values_to = "score") |>
  mutate(timepoint = fct_relevel(timepoint, "post", "pre")) # ensure that factor levels are the in the correct order, especially for d_b

results_sim_1 <- data_simulated_sim_1 |>
  multiple_cohens_ds_for_dependent_data() |>
  select(-hedges_correction) |>
  mutate(ci_width = ci_upper - ci_lower,
         sig = ifelse((ci_lower > 0 & ci_upper > 0) |
                        (ci_lower < 0 & ci_upper < 0) |
                        (is.na(ci_lower) & is.na(ci_upper)), TRUE, FALSE))

results_sim_1 |>
  mutate_if(is.numeric, janitor::round_half_up, digits = 3) |>
  knitr::kable() 

tibble(n,
       mean_pre,
       mean_post,
       sd_pre,
       sd_post,
       r_pre_post) |>
  pivot_longer(cols = everything()) |>
  knitr::kable() 

p_sim_1_all <- ggplot(results_sim_1, aes(paste(type, implementation), estimate, color = sig)) + 
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper), size = 0.8) +
  geom_point(position = position_dodge(width = 0.5), size = 1.8) +
  scale_y_continuous(breaks = seq(-2, 2, 0.1)) +
  coord_flip() +
  theme_linedraw() +
  xlab("") +
  ylab("Cohen's d") +
  scale_color_viridis_d(begin = 0.2, end = 0.5, option = "D") +
  theme(legend.position = "none",
        panel.grid.minor = element_blank())

p_sim_1_all

ggsave(filename = "p_sim_1_all.pdf",
       plot = p_sim_1_all,
       path = "../plots/",
       device = "pdf",
       width = 6,
       height = 6)

```

### Subset 

```{r}

p_sim_1 <- results_sim_1 |>
  filter(!implementation %in% c("{lsr}", "{MBESS}", "{psych}", "{esc}", "{metafor}", "{effsize}", "[custom]") &
           !stringr::str_detect(type, "(alt)")) |>
  ggplot(aes(paste(type, implementation), estimate, color = sig)) + 
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper), size = 0.8) +
  geom_point(position = position_dodge(width = 0.5), size = 1.8) +
  scale_y_continuous(breaks = seq(-2, 2, 0.1)) +
  coord_flip() +
  theme_linedraw() +
  xlab("") +
  ylab("Cohen's d") +
  scale_color_viridis_d(begin = 0.2, end = 0.5, option = "D") +
  theme(legend.position = "none",
        panel.grid.minor = element_blank())

p_sim_1

ggsave(filename = "p_sim_1.pdf",
       plot = p_sim_1,
       path = "../plots/",
       device = "pdf",
       width = 6,
       height = 3)

```

## Sim 2

```{r}

set.seed(42) 

# parameters
n <- 1000 # number of participants
mean_pre <- 0 # mean for pre-test scores
mean_post <- 0.2 # mean for pre-test scores
sd_pre <- 0.5 # SD pre-test scores
sd_post <- 1.5 # SD pre-test scores
r_pre_post <- 0.5 # correlation between pre and post

# simulate data 
data_simulated_sim_2 <- 
  faux::rnorm_multi(n, 
                    mu = c(pre = mean_pre, post = mean_post), 
                    sd = c(sd_pre, sd_post), 
                    r = matrix(c(1,          r_pre_post, 
                                 r_pre_post,         1), 
                               ncol = 2)) |>
  rownames_to_column(var = "id") |>
  pivot_longer(cols = -id,
               names_to = "timepoint",
               values_to = "score") |>
  mutate(timepoint = fct_relevel(timepoint, "post", "pre")) # ensure that factor levels are the in the correct order, especially for d_b

results_sim_2 <- data_simulated_sim_2 |>
  multiple_cohens_ds_for_dependent_data() |>
  select(-hedges_correction) |>
  mutate(ci_width = ci_upper - ci_lower,
         sig = ifelse((ci_lower > 0 & ci_upper > 0) |
                        (ci_lower < 0 & ci_upper < 0) |
                        (is.na(ci_lower) & is.na(ci_upper)), TRUE, FALSE))

results_sim_2 |>
  mutate_if(is.numeric, janitor::round_half_up, digits = 3) |>
  knitr::kable()

tibble(n,
       mean_pre,
       mean_post,
       sd_pre,
       sd_post,
       r_pre_post) |>
  pivot_longer(cols = everything()) |>
  knitr::kable() 

ggplot(results_sim_2, aes(paste(type, implementation), estimate, color = sig)) + 
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper)) +
  geom_point(position = position_dodge(width = 0.5)) +
  coord_flip() +
  theme_linedraw() +
  xlab("") +
  ylab("Cohen's d") +
  scale_color_viridis_d(begin = 0.2, end = 0.5, option = "D") +
  theme(legend.position = "none")

```

### Subset 

```{r}

p_sim_2 <- results_sim_2 |>
  filter(!implementation %in% c("{lsr}", "{MBESS}", "{psych}", "{esc}", "{metafor}", "{effsize}", "[custom]") &
           !stringr::str_detect(type, "(alt)")) |>
  ggplot(aes(paste(type, implementation), estimate, color = sig)) + 
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper), size = 0.8) +
  geom_point(position = position_dodge(width = 0.5), size = 1.8) +
  scale_y_continuous(breaks = seq(-2, 2, 0.1)) +
  coord_flip() +
  theme_linedraw() +
  xlab("") +
  ylab("Cohen's d") +
  scale_color_viridis_d(begin = 0.2, end = 0.5, option = "D") +
  theme(legend.position = "none",
        panel.grid.minor = element_blank())

p_sim_2

ggsave(filename = "p_sim_2.pdf",
       plot = p_sim_2,
       path = "../plots/",
       device = "pdf",
       width = 6,
       height = 3)

```

## Sim 3

```{r}

set.seed(42) 

# parameters
n <- 1000 # number of participants
mean_pre <- 0 # mean for pre-test scores
mean_post <- 0.2 # mean for pre-test scores
sd_pre <- 1 # SD pre-test scores
sd_post <- 1 # SD pre-test scores

# simulate data 
r_pre_post <- 0.8 # correlation between pre and post

data_simulated_sim_3a <- 
  faux::rnorm_multi(n, 
                    mu = c(pre = mean_pre, post = mean_post), 
                    sd = c(sd_pre, sd_post),
                    r = matrix(c(1,          r_pre_post, 
                                 r_pre_post,         1), 
                               ncol = 2)) |>
  rownames_to_column(var = "id") |>
  pivot_longer(cols = -id,
               names_to = "timepoint",
               values_to = "score") |>
  mutate(timepoint = fct_relevel(timepoint, "post", "pre")) # ensure that factor levels are the in the correct order, especially for d_b


r_pre_post_2 <- 0.2 # correlation between pre and post

data_simulated_sim_3b <- 
  faux::rnorm_multi(n, 
                    mu = c(pre = mean_pre, post = mean_post), 
                    sd = c(sd_pre, sd_post), 
                    r = matrix(c(1,            r_pre_post_2, 
                                 r_pre_post_2,           1), 
                               ncol = 2)) |>
  rownames_to_column(var = "id") |>
  pivot_longer(cols = -id,
               names_to = "timepoint",
               values_to = "score") |>
  mutate(timepoint = fct_relevel(timepoint, "post", "pre")) # ensure that factor levels are the in the correct order, especially for d_b


results_simulation_3a <- data_simulated_sim_3a |>
  multiple_cohens_ds_for_dependent_data() |>
  dplyr::select(-hedges_correction) |>
  mutate(ci_width = ci_upper - ci_lower,
         sig = ifelse((ci_lower > 0 & ci_upper > 0) |
                        (ci_lower < 0 & ci_upper < 0) |
                        (is.na(ci_lower) & is.na(ci_upper)), TRUE, FALSE))

results_simulation_3b <- data_simulated_sim_3b |>
  multiple_cohens_ds_for_dependent_data() |>
  select(-hedges_correction) |>
  mutate(ci_width = ci_upper - ci_lower,
         sig = ifelse((ci_lower > 0 & ci_upper > 0) |
                        (ci_lower < 0 & ci_upper < 0) |
                        (is.na(ci_lower) & is.na(ci_upper)), TRUE, FALSE))


results_simulation_3a |>
  mutate_if(is.numeric, janitor::round_half_up, digits = 3) |>
  knitr::kable()

results_simulation_3b |>
  mutate_if(is.numeric, janitor::round_half_up, digits = 3) |>
  knitr::kable() 


tibble(sim = c(1, 2),
       n,
       mean_pre,
       mean_post,
       sd_pre,
       sd_post,
       r_pre_post = c(r_pre_post, r_pre_post_2)) |>
  pivot_longer(cols = -sim) |>
  pivot_wider(names_from = sim, 
              values_from = value,
              names_prefix = "sim_") |>
  knitr::kable()


ggplot(results_simulation_3a, aes(paste(type, implementation), estimate, color = sig)) + # fct_reorder(type, estimate), estimate
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper)) +
  geom_point(position = position_dodge(width = 0.5)) +
  coord_flip() +
  theme_linedraw() +
  xlab("") +
  ylab("Cohen's d") +
  scale_color_viridis_d(begin = 0.2, end = 0.5, option = "D") +
  theme(legend.position = "none",
        panel.grid.minor = element_blank())

ggplot(results_simulation_3b, aes(paste(type, implementation), estimate, color = sig)) + # fct_reorder(type, estimate), estimate
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper)) +
  geom_point(position = position_dodge(width = 0.5)) +
  coord_flip() +
  theme_linedraw() +
  xlab("") +
  ylab("Cohen's d") +
  scale_color_viridis_d(begin = 0.2, end = 0.5, option = "D") +
  theme(legend.position = "none",
        panel.grid.minor = element_blank())

```

### Subset 

```{r}

p_sim_3a <- results_simulation_3a |>
  filter(!implementation %in% c("{lsr}", "{MBESS}", "{psych}", "{esc}", "{metafor}", "{effsize}", "[custom]") &
           !stringr::str_detect(type, "(alt)")) |>
  ggplot(aes(paste(type, implementation), estimate, color = sig)) + 
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper), size = 0.8) +
  geom_point(position = position_dodge(width = 0.5), size = 1.8) +
  scale_y_continuous(breaks = seq(-2, 2, 0.2)) +
  coord_flip() +
  theme_linedraw() +
  xlab("") +
  ylab("Cohen's d") +
  scale_color_viridis_d(begin = 0.2, end = 0.5, option = "D") +
  theme(legend.position = "none",
        panel.grid.minor = element_blank())

p_sim_3a

ggsave(filename = "p_sim_3a.pdf",
       plot = p_sim_3a,
       path = "../plots/",
       device = "pdf",
       width = 6,
       height = 3)


results_simulation_3b |>
  filter(!implementation %in% c("{lsr}", "{MBESS}", "{psych}", "{esc}", "{metafor}", "{effsize}", "[custom]") &
           !stringr::str_detect(type, "(alt)")) |>
  ggplot(aes(paste(type, implementation), estimate, color = sig)) + 
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper)) +
  geom_point(position = position_dodge(width = 0.5)) +
  scale_y_continuous(breaks = seq(-2, 2, 0.2)) +
  coord_flip() +
  theme_linedraw() +
  xlab("") +
  ylab("Cohen's d") +
  scale_color_viridis_d(begin = 0.2, end = 0.5, option = "D") +
  theme(legend.position = "none",
        panel.grid.minor = element_blank())

```

### high correlation condition only - alt plots

```{r}

results_simulation_3a |>
  mutate(type_implementation = paste(type, implementation),
         type_implementation = fct_reorder(type_implementation, estimate)) |>
  ggplot(aes(type_implementation, estimate)) + 
  #geom_hline(yintercept = 0, linetype = "dashed") +
  #geom_linerange(aes(ymin = ci_lower, ymax = ci_upper)) +
  geom_point() +
  coord_flip() +
  theme_linedraw() +
  xlab("") +
  ylab("Cohen's d")

results_simulation_3a |>
  drop_na() |>
  mutate(type_implementation = paste(type, implementation),
         type_implementation = fct_reorder(type_implementation, ci_width)) |>
  ggplot(aes(type_implementation, ci_width)) +
  #geom_hline(yintercept = 0, linetype = "dashed") +
  #geom_linerange(aes(ymin = ci_lower, ymax = ci_upper)) +
  geom_point() +
  coord_flip() +
  theme_linedraw() +
  xlab("") +
  ylab("Cohen's d CI width")

```

### High condition only - just {effectsize}'s metrics

```{r}

results_simulation_3a |>
  filter(implementation == "{effectsize}") |>
  ggplot(aes(type, estimate, color = sig)) + # fct_reorder(type, estimate), estimate
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper), size = 0.8) +
  geom_point(position = position_dodge(width = 0.5), size = 1.8) +
  scale_y_continuous(breaks = seq(-2, 2, 0.2)) +
  coord_flip() +
  theme_linedraw() +
  xlab("") +
  ylab("Cohen's d") +
  scale_color_viridis_d(begin = 0.2, end = 0.5, option = "D") +
  theme(legend.position = "none",
        panel.grid.minor = element_blank())

```

## Sim 4

```{r}

set.seed(42) 

# parameters
n <- 1000 # number of participants
mean_pre <- 1.5 # mean for pre-test scores
mean_post <- 6.5 # mean for pre-test scores
sd_pre <- 1.5 # SD pre-test scores
sd_post <- 1.5 # SD pre-test scores
r_pre_post <- -0.75 # correlation between pre and post

# simulate data 
data_simulated_sim_4 <- 
  faux::rnorm_multi(n, 
                    mu = c(pre = mean_pre, post = mean_post), 
                    sd = c(sd_pre, sd_post), 
                    r = matrix(c(1,          r_pre_post, 
                                 r_pre_post,         1), 
                               ncol = 2)) |>
  rownames_to_column(var = "id") |>
  pivot_longer(cols = -id,
               names_to = "timepoint",
               values_to = "score") |>
  mutate(timepoint = fct_relevel(timepoint, "post", "pre")) # ensure that factor levels are the in the correct order, especially for d_b

results_sim_4 <- data_simulated_sim_4 |>
  multiple_cohens_ds_for_dependent_data() |>
  select(-hedges_correction) |>
  mutate(ci_width = ci_upper - ci_lower,
         sig = ifelse((ci_lower > 0 & ci_upper > 0) |
                        (ci_lower < 0 & ci_upper < 0) |
                        (is.na(ci_lower) & is.na(ci_upper)), TRUE, FALSE))

results_sim_4 |>
  mutate_if(is.numeric, janitor::round_half_up, digits = 3) |>
  knitr::kable() 

tibble(n,
       mean_pre,
       mean_post,
       sd_pre,
       sd_post,
       r_pre_post) |>
  pivot_longer(cols = everything()) |>
  knitr::kable() 

p_sim_4_all <- ggplot(results_sim_4, aes(paste(type, implementation), estimate, color = sig)) + 
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper), size = 0.8) +
  geom_point(position = position_dodge(width = 0.5), size = 1.8) +
  scale_y_continuous(breaks = seq(-12, 12, 1)) +
  coord_flip() +
  theme_linedraw() +
  xlab("") +
  ylab("Cohen's d") +
  scale_color_viridis_d(begin = 0.2, end = 0.5, option = "D") +
  theme(legend.position = "none",
        panel.grid.minor = element_blank())

p_sim_4_all

ggsave(filename = "p_sim_4_all.pdf",
       plot = p_sim_4_all,
       path = "../plots/",
       device = "pdf",
       width = 6,
       height = 6)

```

### Subset 

```{r}

p_sim_4 <- results_sim_4 |>
  filter(!implementation %in% c("{lsr}", "{MBESS}", "{psych}", "{esc}", "{metafor}", "{effsize}", "[custom]") &
           !stringr::str_detect(type, "(alt)")) |>
  ggplot(aes(paste(type, implementation), estimate, color = sig)) + 
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper), size = 0.8) +
  geom_point(position = position_dodge(width = 0.5), size = 1.8) +
  scale_y_continuous(breaks = seq(-12, 12, 1)) +
  coord_flip() +
  theme_linedraw() +
  xlab("") +
  ylab("Cohen's d") +
  scale_color_viridis_d(begin = 0.2, end = 0.5, option = "D") +
  theme(legend.position = "none",
        panel.grid.minor = element_blank())

p_sim_4

# ggsave(filename = "p_sim_4.pdf",
#        plot = p_sim_4,
#        path = "../plots/",
#        device = "pdf",
#        width = 6,
#        height = 3)

```

# Session info

```{r}

sessionInfo()

```

