---
title: "General structure of a simulation study"
subtitle: "Part 2: Do it lots of times, summarize across iterations, and make it an experiment [assignment]"
author: "[students: replace this text and brackets with your name]"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    code_download: true
    code_folding: show
    highlight: haddock
    theme: flatly
    toc: yes
    toc_float: yes
---

GENERAL FEEDBACK WAS THIS WAS TOO EASY - CHANGE NEXT YEAR

# Overview of tutorial

This lesson covers the steps of writing functions for the remaining essential components of a simulation study within the workflow we will use throughout this course: doing the generate and analyze steps many times, summarizing results across iterations, and making it an experiment.

# Citation & License

Citation: 

Ian Hussey (2024) Improving your statistical inferences through simulation studies in R. https://github.com/ianhussey/simulation-course

License: 

[CC BY 4.0](https://creativecommons.org/licenses/by/4.0/deed.en)

```{r, include=FALSE}

# set default chunk options
knitr::opts_chunk$set(message = FALSE,
                      warning = FALSE)

# disable scientific notation
options(scipen = 999) 

```

# Dependencies

```{r}

library(tidyr)
library(dplyr)
library(forcats)
library(readr)
library(purrr) 
library(ggplot2)
library(scales)
library(knitr)
library(kableExtra)

```

# Putting it all together

The full {purrr} based workflow from the lesson.

```{r}

# remove all objects from environment to ensure you're starting from a blank page
rm(list = ls())

# set seed
set.seed(42)

# functions for simulation
generate_data <- function(n_per_condition,
                          mean_control,
                          mean_intervention,
                          sd) {
  
  data_control <- 
    tibble(condition = "control",
           score = rnorm(n = n_per_condition, mean = mean_control, sd = sd))
  
  data_intervention <- 
    tibble(condition = "intervention",
           score = rnorm(n = n_per_condition, mean = mean_intervention, sd = sd))
  
  data_combined <- bind_rows(data_control,
                             data_intervention)
  
  return(data_combined)
}

analyze <- function(data) {

  res_t_test <- t.test(formula = score ~ condition, 
                       data = data,
                       var.equal = TRUE,
                       alternative = "two.sided")
  
  res <- tibble(p = res_t_test$p.value)
  
  return(res)
}

# simulation parameters
experiment_parameters <- expand_grid(
  n_per_condition = 50,
  mean_control = 0,
  mean_intervention = c(0, 0.5),
  sd = 1,
  iteration = 1:1000 
) |>
  # because mean_control is 0 and both SDs are 1, mean_intervention is really a proxy for Cohen's d
  # because d = [mean_intervention - mean_control]/SD_pooled
  # for clarity, let's just make a variable called population_effect_size
  mutate(population_effect_size = paste0("Cohen's d = ", mean_intervention)) 

# run simulation
simulation <- experiment_parameters |>
  mutate(generated_data = pmap(list(n_per_condition, 
                                    mean_control,
                                    mean_intervention,
                                    sd),
                               generate_data)) |>
  mutate(results = pmap(list(generated_data),
                        analyze))

# summarize across iterations
simulation_summary <- simulation |>
  # unnest results
  unnest(results) |>
  # for each level of mean_intervention... 
  group_by(population_effect_size) |>
  # ... calculate proportion of iterations where significant results were found
  mutate(significant = p < .05) |>
  summarize(proportion_of_significant_p_values = mean(significant))

# table of results
simulation_summary |>
  kable() |>
  kable_classic(full_width = FALSE)

# plot results
ggplot(simulation_summary, aes(population_effect_size, proportion_of_significant_p_values)) +
  geom_col() +
  theme_linedraw() +
  scale_y_continuous(breaks = breaks_pretty(n = 10),
                     limits = c(0,1),
                     name = "Proportion of significant p-values") +
  scale_x_discrete(name = "Population effect size")

```

- The false-positive rate of a Student's t-test (proportion of significant results when population effect is zero) is 5% *when all assumptions of the test are met*. This is as it should be: false positive rate should == the test's alpha value.
- The true-positive rate of a Student's t-test (proportion of significant results when population effect is non-zero) is c.67% when all assumptions of the test are met, the population effect size is Cohen's *d* = 0.5, and there are 50 participants per group. In other words, the statistical power of the test (the probability of detecting effects that exist) is about .67 under these conditions. 

# Homework / assignment

Note that both of the below simulation assignments are what Siepe et al. (2024) refer to as one-at-a-time simulations. 

*Ensure that your code runs!* Click 'knit' and make sure that it creates a .html file with results rather than throwing errors and stopping. This is the first thing I will check when marking the assignments. A primary goal of this class is to be able to write reproducible results.

## Part 1

Write a separate modified version of the original simulation above which, instead of experimentally manipulating the population Cohen's *d* between conditions, instead always uses a Cohen's *d* of 0.5. Instead, manipulate the number of participants per condition. What is the statistical power for population Cohen's *d* = 0.5 for 25, 50, 75, and 100 participants per condition? Copy, paste, and change the code from the "putting it all together" chunk above to summarize the results across the iterations to summarize these results. Return a table/or plot of the results, ideally both.

- Think about what aspects of the simulation you will need to alter versus not.
- Use the same set.seed() value as I do so that we obtain identical results.

```{r}


```

## Part 2

Write a modified version of the original simulation to also extract the estimate of Cohen's *d*. Copy, paste, and change the code from the "putting it all together" chunk above to summarize the results across the iterations to do parameter recovery on Cohen's *d*: what is the observed mean Cohen's *d* between the conditions? 

- You will have to alter the data analysis function and how you summarize across iterations.
- Use the same set.seed() value as I do so that we obtain identical results.

```{r}


```

# Session info

```{r}

sessionInfo()

```


