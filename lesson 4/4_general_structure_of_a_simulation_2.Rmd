---
title: "General structure of a simulation study"
subtitle: "Part 2: Do it lots of times, summarize across iterations, and make it an experiment"
author: "Ian Hussey"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    code_download: true
    code_folding: show
    highlight: haddock
    theme: flatly
    toc: yes
    toc_float: yes
---

# Overview of tutorial

This lesson covers the steps of writing functions for the remaining essential components of a simulation study within the workflow we will use throughout this course: doing the generate and analyze steps many times, summarizing results across iterations, and making it an experiment.

# Citation & License

Citation: 

Ian Hussey (2024) Improving your statistical inferences through simulation studies in R. https://github.com/ianhussey/simulation-course

License: 

[CC BY 4.0](https://creativecommons.org/licenses/by/4.0/deed.en)

```{r, include=FALSE}

# set default chunk options
knitr::opts_chunk$set(message = FALSE,
                      warning = FALSE)

# disable scientific notation
options(scipen = 999) 

```

# Dependencies

```{r}

library(tidyr)
library(dplyr)
library(forcats)
library(readr)
library(purrr) 
library(ggplot2)
library(scales)
library(knitr)
library(kableExtra)

```

# Generate data and analyze functions from last lesson

```{r}

generate_data <- function(n_per_condition,
                          mean_control,
                          mean_intervention,
                          sd) {
  
  data_control <- 
    tibble(condition = "control",
           score = rnorm(n = n_per_condition, mean = mean_control, sd = sd))
  
  data_intervention <- 
    tibble(condition = "intervention",
           score = rnorm(n = n_per_condition, mean = mean_intervention, sd = sd))
  
  data_combined <- bind_rows(data_control,
                             data_intervention)
  
  return(data_combined)
}


analyze <- function(data) {

  res_t_test <- t.test(formula = score ~ condition, 
                       data = data,
                       var.equal = TRUE,
                       alternative = "two.sided")
  
  res <- tibble(p = res_t_test$p.value)
  
  return(res)
}

```

# Do it once

```{r}

results <- 
  generate_data(n_per_condition = 50,
                mean_control = 0,
                mean_intervention = 0.5,
                sd = 1) |>
  analyze()

```

Note that this is equivalent to the below, which just reformats the code:

```{r}

results <- generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze()

```

# Do it lots of times and make it an experiment [bad]

Let's use our functions to understand the same question we asked in the first lesson: what is the distribution of *p* values under the null vs. alternative hypothesis. 

To do this we need to a) do it a lot of times and b) make it an experiment.

We'll start by doing this in a stupid way. 25 iterations of the simulation by repeating our functions 25 times.

```{r}

results_null <- 
  bind_rows(
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0, sd = 1) |> analyze()
  )

results_alternative <- 
  bind_rows(
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze(),
    generate_data(n_per_condition = 50, mean_control = 0, mean_intervention = 0.5, sd = 1) |> analyze()
  )

# plots
ggplot(results_null, aes(p)) +
  geom_histogram() +
  ggtitle("Distribution of p values under the null hypothesis\n(Population Cohen's d = 0.0)")

ggplot(results_alternative, aes(p)) +
  geom_histogram() +
  ggtitle("Distribution of p values under the alternative hypothesis\n(Population Cohen's d = 0.5)")

# proportion of significant p values
mean(results_null$p <.05)

mean(results_alternative$p <.05)

```


# Do it lots of times and make it an experiment [good]

## Part 1 of the solution: {tidyr}'s `expand_grid()`

`expand_grid()` is extremely useful because it creates all possible permutations of all variables you provide it with. 

It is used to create the set of all conditions and iterations you want to simulate using your data generation and analysis functions. For the moment, we will only create the conditions and iterations.

```{r}

expand_grid(
  time_point = c("pre", "post"),
  condition = c("control", "intervention") 
) 

```

It's even more useful when you want to repeat the same information on a lot of rows:

```{r}

# create the sequence from 1 to 100
iterations <- seq(from = 1, to = 100, by = 1)

# check
iterations
# add these iterations to the expand_grid() call
grid <- expand_grid(
  time_point = c("pre", "post"),
  condition = c("control", "intervention"),
  iteration = iterations
) 

View(grid)

```

Note that I can more simply specify the iterations `seq(from = 1, to = 100, by = 1)` as `1:100`.

```{r}

# add these iterations to the expand_grid() call
grid <- expand_grid(
  time_point = c("pre", "post"),
  condition = c("control", "intervention"),
  iteration = 1:100 # note this is a series not an integer, i.e., "1:100" not "100", as "100" would mean just one iteration called "100".
) 

View(grid)

```

### Use `expand_grid()` to create a tibble 

With:

- 100 iterations of:
- n per condition = 50
- mean control of 0
- mean intervention of 0.5
- SD of 1

#### Try it yourself first

```{r eval=FALSE, include=FALSE}



```

#### Solution

```{r}

experiment_parameters <- expand_grid(
  n_per_condition = 50,
  mean_control = 0,
  mean_intervention = 0.5,
  sd = 1,
  iteration = 1:100 
) 

```

### How would we make this an experiment?

Modify the `expand_grid()` so that it can be used to simulate not only mean_intervention = 0.5 but also 0. 

#### Try it yourself first

```{r eval=FALSE, include=FALSE}



```

#### Solution

```{r}

experiment_parameters <- expand_grid(
  n_per_condition = 50,
  mean_control = 0,
  mean_intervention = c(0, 0.5),
  sd = 1,
  iteration = 1:100 
) 

```

- Note that `expand_grid()` effectively creates a full-factorial simulation, following Siepe et al.'s (2024) definition.

## Part 2 of the solution: {purrr}'s `pmap()`

### Use `pmap()` to map a function and *output* a nested data frame

`pmap()` aka 'parallel map' can be used to map an arbitrary number of inputs from columns in a tibble onto a function. It returns a data frame. It also plays nice with `mutate()` and other tidyverse functions. 

However, it complicates things by introducing the concept of nested data frames. Run the chunk below and then view the tibble to see what I mean. 

```{r}

simulation <- experiment_parameters |>
  mutate(generated_data = pmap(list(n_per_condition, 
                                    mean_control,
                                    mean_intervention,
                                    sd),
                               generate_data))

View(simulation)

```

We are used to data frames where the value of a given cell (i.e., a given row of a given column) is a numeric, character, or logical value - i.e. a number, a string of letters, or maybe TRUE/FALSE.

Data frames can technically contain anything though, even other data frames. Nested data frames are data frames whose cells contain other data frames.

„Gott im Himmel!“, „Hopp de Bäse!“ I hear you cry. Why would we want to do this?? 

**Note: stop here and show slides on tidy nested data**

### Viewing and extracting nested data frames

In the data viewer, you can click on a cell containing a data frame to view its contents in a new viewer window.

You can also access these data frames using `containing_data_frame$nested_data_frame_column[[rownumber]]`:

```{r}

# extract a single data set and assign it to its own object
data_set_iteration_1 <- simulation$generated_data[[1]]

# use this extracted data frame in the analyze function
analyze(data_set_iteration_1)

```

### Use `pmap()` to use a nested data frame as the *input* for a a function

You can also use nested data frames as inputs to other functions, not just outputs. This is also done via `pmap()`. 

Being able to use them as both inputs and outputs makes them very powerful. 

```{r}

simulation <- experiment_parameters |>
  mutate(generated_data = pmap(list(n_per_condition, 
                                    mean_control,
                                    mean_intervention,
                                    sd),
                               generate_data)) |>
  mutate(results = pmap(list(generated_data),
                        analyze)) 

View(simulation)

```

### Transparency vs. data size

```{r}

simulation |>
  object.size() |>
  format(units = "auto")

simulation |>
  select(-generated_data) |>
  object.size() |>
  format(units = "auto")

```

### Common mistake with `pmap()`

`pmap()` takes *ordered* inputs *not named* inputs. It does not know or understand if you pass it arguments in the wrong order, it will use them anyway. If the function can use it will fail silently and produce nonsense results.

For example, this code will run because all the arguments are numeric, but I have put them in the list in the wrong order.  

```{r}

simulation_wrong_input <- experiment_parameters |>
  mutate(generated_data = pmap(list(n_per_condition, 
                                    mean_intervention,
                                    mean_control,
                                    sd),          # order supplied: n_per_condition, mean_intervention, mean_control,      sd
                               generate_data)) |> # order expected: n_per_condition, mean_control,      mean_intervention, sd
  mutate(results = pmap(list(generated_data),
                        analyze)) 

```

## Flatten / unnest a nested data frames 

Flatten / unnest a nested data frames into the containing data frame.

```{r}

simulation_summary <- simulation |>
  unnest(results)

```

# Summarize across iterations

Note that this step will be much less standardized between simulations. You will have to adjust this code quite a lot to do what you need it to compared to the relatively standardized workflow for generate data and analyze data. Summarizing the data across iterations depends heavily what your simulation's experimental conditions and research questions are. 

```{r}

# summarize across iterations
simulation_summary <- simulation |>
  unnest(results) |>
  # because mean_control is 0 and both SDs are 1, mean_intervention is really a proxy for Cohen's d 
  # because d = [mean_intervention - mean_control]/SD_pooled
  # for clarity, let's just make a variable called population_effect_size
  mutate(population_effect_size = paste0("Cohen's d = ", mean_intervention))|> 
  # for each level of mean_intervention... 
  group_by(population_effect_size) |>
  # ... calculate proportion of iterations where significant results were found
  mutate(significant = p < .05) |>
  summarize(power = mean(significant))

# plot results
ggplot(simulation_summary, aes(population_effect_size, power)) +
  geom_col() +
  theme_linedraw() +
  scale_y_continuous(breaks = breaks_pretty(n = 10),
                     limits = c(0,1),
                     name = "Proportion of significant p-values") +
  scale_x_discrete(name = "Population effect size")

```

- Comprehension question: What do these two columns represent? They are well known statistical properties that you have just simulated.

## Common mistake

You must group by the things you manipulated in the expand grid! I can't give you an example for this yet, but remember this as an essential step. If you set up an simulation experiment manipulating two variables but then summarize the results over just one of them the results will be meaningless or at least very hard to interpret.

# Putting it all together

```{r}

# remove all objects from environment to ensure you're starting from a blank page
rm(list = ls())

# set seed
set.seed(42)

# functions for simulation
generate_data <- function(n_per_condition,
                          mean_control,
                          mean_intervention,
                          sd) {
  
  data_control <- 
    tibble(condition = "control",
           score = rnorm(n = n_per_condition, mean = mean_control, sd = sd))
  
  data_intervention <- 
    tibble(condition = "intervention",
           score = rnorm(n = n_per_condition, mean = mean_intervention, sd = sd))
  
  data_combined <- bind_rows(data_control,
                             data_intervention)
  
  return(data_combined)
}

analyze <- function(data) {

  res_t_test <- t.test(formula = score ~ condition, 
                       data = data,
                       var.equal = TRUE,
                       alternative = "two.sided")
  
  res <- tibble(p = res_t_test$p.value)
  
  return(res)
}

# simulation parameters
experiment_parameters <- expand_grid(
  n_per_condition = 50,
  mean_control = 0,
  mean_intervention = c(0, 0.5),
  sd = 1,
  iteration = 1:10000 # note that number of iterations has been increased to provide more stable estimates / lower monte-carlo error. 
) |>
  # because mean_control is 0 and both SDs are 1, mean_intervention is really a proxy for Cohen's d
  # because d = [mean_intervention - mean_control]/SD_pooled
  # for clarity, let's just make a variable called population_effect_size
  mutate(population_effect_size = paste0("Cohen's d = ", mean_intervention)) 

# run simulation
simulation <- experiment_parameters |>
  mutate(generated_data = pmap(list(n_per_condition, 
                                    mean_control,
                                    mean_intervention,
                                    sd),
                               generate_data)) |>
  mutate(results = pmap(list(generated_data),
                        analyze))

# summarize across iterations
simulation_summary <- simulation |>
  # unnest results
  unnest(results) |>
  # for each level of mean_intervention... 
  group_by(population_effect_size) |>
  # ... calculate proportion of iterations where significant results were found
  mutate(significant = p < .05) |>
  summarize(proportion_of_significant_p_values = mean(significant))

# table of results
simulation_summary |>
  kable() |>
  kable_classic(full_width = FALSE)

# plot results
ggplot(simulation_summary, aes(population_effect_size, proportion_of_significant_p_values)) +
  geom_col() +
  theme_linedraw() +
  scale_y_continuous(breaks = breaks_pretty(n = 10),
                     limits = c(0,1),
                     name = "Proportion of significant p-values") +
  scale_x_discrete(name = "Population effect size")

```

- The false-positive rate of a Student's t-test (proportion of significant results when population effect is zero) is 5% *when all assumptions of the test are met*. This is as it should be: false positive rate should == the test's alpha value.
- The true-positive rate of a Student's t-test (proportion of significant results when population effect is non-zero) is c.67% when all assumptions of the test are met, the population effect size is Cohen's *d* = 0.5, and there are 50 participants per group. In other words, the statistical power of the test (the probability of detecting effects that exist) is about .67 under these conditions. 

## Check your own learning

- How do I know that all the test's assumptions have been met? 
- What are a Student's *t*-test's assumptions?

...What happens if these assumptions aren't met? We will cover this in the next class. 

# Distribution of *p* values

Let's return to the question we answered in the first lecture on using simulation to understand the distribution of *p*-values under the alternative vs. null hypothesis, but this time using the results of the tidy simulation above.

Remember: this just plots the data in a different way to the above, but expresses the same information (the false-positive and true-positive rate). Plotting it the below way helps illustrate *why* the false-positive and false-negative rates are why they are. 

```{r}

# function to extract and plot p values
plot_p_values <- function(data){ # assumes that data is a data frame with a column "p"
  data |>
    mutate(decision = ifelse(p < .05, "significant", "non-significant")) |>
    ggplot(aes(p, fill = decision)) +
    geom_histogram(binwidth = 0.05, boundary = 0) +
    scale_fill_viridis_d(option = "mako", begin = 0.3, end = 0.7, direction = -1) +
    scale_x_continuous(labels = c(0, 0.05, 0.25, 0.50, 0.75, 1.0),
                       breaks = c(0, 0.05, 0.25, 0.50, 0.75, 1.0), 
                       limits = c(0, 1)) +
    theme_linedraw() +
    ylab("Frequency") +
    xlab("p value")
}

simulation |>
  unnest(results) |>
  filter(population_effect_size == "Cohen's d = 0") |>
  plot_p_values() +
  ggtitle("Distribution of p values under the null hypothesis")

simulation |>
  unnest(results) |>
  filter(population_effect_size == "Cohen's d = 0.5") |>
  plot_p_values() +
  ggtitle("Distribution of p values under the alternative hypothesis")

```

# Session info

```{r}

sessionInfo()

```


