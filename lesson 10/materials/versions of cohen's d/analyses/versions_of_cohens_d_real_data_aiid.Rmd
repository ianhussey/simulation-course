---
title: "Versions of Cohen's *d* for dependent data"
author: "Ian Hussey & Jamie Cummins"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    code_folding: hide
    highlight: haddock
    theme: flatly
    toc: yes
    toc_float: yes
---

# TODO

- rstatix effect sizes aren't included as they use bootstrapping, and in this context that would have taken a long time to run.
- the d from test statistic effect sizes aren't included as they threw errors and i didn't get around to bug fixing them.


```{r include=FALSE}

knitr::opts_chunk$set(message = FALSE, 
                      warning = FALSE)

options(scipen=999)

```

# Dependencies 

N.B.: to ensure full computational reproducibility, R version 4.3.3 should be used. 

```{r}

library(groundhog)

groundhog_day = "2024-04-07"

packages = c("effectsize","faux","janitor",
             "readr",
             "rstatix", "effsize",
             "psych", "MBESS", "lsr",
             "metafor", "esc", "esci",
             "dplyr", "tidyr", "tibble",
             "forcats", "ggplot2", "stringr", 
             "purrr")

groundhog.library(packages, groundhog_day)


load("../data/AIID_subset_confirmatory.RData")

# dat <- AIID_subset_confirmatory |>
#   filter(exclude_iat_stricter == FALSE) |>
#   select(session_id, domain, prefer, 
#          positive_x, positive_y, 
#          warm_x, warm_y, 
#          like_x, like_y) |>
#   pivot_longer(cols = c("positive_x", "positive_y", "warm_x", "warm_y", "like_x", "like_y"),
#                names_to = c("dimension", "object"),
#                values_to = "rating",
#                names_sep = "_") |>
#   pivot_wider(names_from = "object", 
#               values_from = "rating") |>
#   drop_na() |>
#   rename(id = session_id,
#          pre = x,
#          post = y) # for convenience, to not change code below
# 
# 
# summary <- dat |>
#   group_by(domain) %>%
#   summarize(r = cor(pre, post, method = "pearson"), 
#             n = n(),
#             mean_x = mean(pre),
#             mean_y = mean(post),
#             sd_x = sd(pre),
#             sd_y = sd(post),
#             .groups = 'drop')
# 
# 
# ggplot(summary, aes(r)) +
#   geom_density() +
#   geom_vline(xintercept = 0, linetype = "dashed")



dat_for_versions <- AIID_subset_confirmatory |>
  filter(exclude_iat_stricter == FALSE) |>
  select(id = session_id, domain, prefer, 
         positive_x, positive_y, 
         warm_x, warm_y, 
         like_x, like_y) |>
  pivot_longer(cols = c("positive_x", "positive_y", "warm_x", "warm_y", "like_x", "like_y"),
               names_to = c("item", "timepoint"),
               values_to = "score",
               names_sep = "_") |>
  mutate(timepoint = case_when(timepoint == "x" ~ "pre",
                               timepoint == "y" ~ "post")) |>
  select(id, domain, timepoint, score) |>
  drop_na() |>
  # widen and then drop case and then lengthen again to ensure we keep only ids with both ratings
  pivot_wider(names_from = timepoint,
              values_from = score) |>
  drop_na() |>
  pivot_longer(cols = c("pre", "post"),
               names_to = "timepoint",
               values_to = "score")

```

# Functions

```{r}

round_half_up_min_decimals <- function(x, digits = 2) {
  sprintf(paste0("%.", digits, "f"), janitor::round_half_up(x, digits = digits))
}

cohens_d_s_metafor <- function(data){
  # nb always applies hedges correction
  require(dplyr)
  require(tibble)
  require(metafor)
  
  summaries <- data |>
    group_by(timepoint) |>
    summarize(mean = mean(score),
              sd = sd(score),
              n = n()) |>
    pivot_wider(names_from = "timepoint",
                values_from = c("mean", "sd", "n"))
  
  fit <- escalc(measure = "SMD", 
                m1i = mean_post, 
                sd1i = sd_post, 
                n1i = n_post,
                m2i = mean_pre, 
                sd2i = sd_pre, 
                n2i = n_pre, 
                data = summaries, 
                append = FALSE)
  
  res <- 
    tibble(estimate = fit$yi,
           ci_lower = fit$yi - sqrt(fit$vi)*1.96,
           ci_upper = fit$yi + sqrt(fit$vi)*1.96)
  return(res)
}


cohens_d_s_esc <- function(data, hedges_correction = TRUE){
  require(dplyr)
  require(tibble)
  require(esc)
  
  summaries <- data |>
    group_by(timepoint) |>
    summarize(mean = mean(score),
              sd = sd(score),
              n = n())
  
  fit <- esc::esc_mean_sd(grp1m  = summaries$mean[summaries$timepoint == "post"],
                          grp1sd = summaries$sd[summaries$timepoint == "post"],
                          grp1n  = summaries$n[summaries$timepoint == "post"],
                          grp2m  = summaries$mean[summaries$timepoint == "pre"],
                          grp2sd = summaries$sd[summaries$timepoint == "pre"],
                          grp2n  = summaries$n[summaries$timepoint == "pre"],
                          es.type = ifelse(hedges_correction, "g", "d"))
  
  res <- 
    tibble(estimate = fit$es,
           ci_lower = fit$ci.lo,
           ci_upper = fit$ci.hi)
  
  return(res)
}


cohens_d_z_esc <- function(data, hedges_correction = TRUE){
  require(dplyr)
  require(tibble)
  require(esc)
  
  summaries <- data |>
    group_by(timepoint) |>
    summarize(mean = mean(score),
              sd = sd(score),
              n = n())
  
  r <- data |>
    pivot_wider(names_from = "timepoint",
                values_from = "score") |>
    dplyr::select(-id) |>
    cor_test()
  
  fit <- esc::esc_mean_sd(grp1m  = summaries$mean[summaries$timepoint == "post"],
                          grp1sd = summaries$sd[summaries$timepoint == "post"],
                          grp1n  = summaries$n[summaries$timepoint == "post"],
                          grp2m  = summaries$mean[summaries$timepoint == "pre"],
                          grp2sd = summaries$sd[summaries$timepoint == "pre"],
                          grp2n  = summaries$n[summaries$timepoint == "pre"],
                          r = r$cor,
                          es.type = ifelse(hedges_correction, "g", "d"))
  
  res <- 
    tibble(estimate = fit$es,
           ci_lower = fit$ci.lo,
           ci_upper = fit$ci.hi)
  
  return(res)
}


# cohens_d_s_rstatix <- function(data, hedges_correction = TRUE){
#   require(dplyr)
#   require(tibble)
#   require(rstatix)
#   
#   fit <- rstatix::cohens_d(formula = score ~ timepoint,
#                            data = data,
#                            comparisons = list(c("pre", "post")),
#                            ref.group = "post",
#                            paired = FALSE,
#                            hedges.correction = hedges_correction,
#                            ci = TRUE,
#                            ci.type = "bca",
#                            nboot = 2000)
#   
#   res <- 
#     tibble(estimate = fit$effsize,
#            ci_lower = fit$conf.low,
#            ci_upper = fit$conf.high)
#   
#   return(res)
# }


# cohens_d_z_rstatix <- function(data, hedges_correction = TRUE){
#   require(dplyr)
#   require(tibble)
#   require(rstatix)
#   
#   fit <- rstatix::cohens_d(formula = score ~ timepoint,
#                            data = data,
#                            comparisons = list(c("pre", "post")),
#                            ref.group = "post",
#                            paired = TRUE,
#                            hedges.correction = hedges_correction,
#                            ci = TRUE,
#                            ci.type = "bca",
#                            nboot = 2000)
#   
#   res <- 
#     tibble(estimate = fit$effsize,
#            ci_lower = fit$conf.low,
#            ci_upper = fit$conf.high)
#   
#   return(res)
# }


# esci used to have a within subjects d in 2020 but now doesn't? and its not in the git history
cohens_d_s_esci <- function(data, hedges_correction = TRUE){
  require(dplyr)
  require(tibble)
  require(esci)
  
  summaries <- data |>
    group_by(timepoint) |>
    summarize(mean = mean(score),
              sd = sd(score),
              n = n())
  
  fit <- esci::CI_smd_ind_contrast(means = summaries$mean,
                                   sds = summaries$sd,
                                   ns = summaries$n,
                                   contrast = c(+1, -1),
                                   conf_level = 0.95,
                                   assume_equal_variance = FALSE,
                                   correct_bias = hedges_correction)
  
  res <- 
    tibble(estimate = fit$effect_size,
           ci_lower = fit$LL,
           ci_upper = fit$UL)
  
  return(res)
}


cohens_d_s_effsize <- function(data, hedges_correction = TRUE){
  require(dplyr)
  require(tibble)
  require(effsize)
  
  fit <- effsize::cohen.d(score ~ timepoint, 
                          paired = FALSE,
                          pooled = TRUE,
                          hedges.correction = hedges_correction,
                          data = data)
  
  res <- 
    tibble(estimate = fit$estimate,
           ci_lower = fit$conf.int[1],
           ci_upper = fit$conf.int[2])
  
  return(res)
}


cohens_d_dep_effsize <- function(data, hedges_correction = TRUE){
  require(dplyr)
  require(tibble)
  require(effsize)
  
  fit <- effsize::cohen.d(score ~ timepoint | Subject(id), 
                          paired = TRUE,
                          pooled = TRUE,
                          hedges.correction = hedges_correction,
                          data = data)
  
  res <- 
    tibble(estimate = fit$estimate,
           ci_lower = fit$conf.int[1],
           ci_upper = fit$conf.int[2])
  
  return(res)
}



cohens_d_s_psych <- function(data, hedges_correction = TRUE){
  require(dplyr)
  require(tibble)
  require(psych)
  
  fit <- psych::cohen.d(score ~ timepoint,
                        data = data) 
  
  res <- 
    tibble(estimate = ifelse(hedges_correction, fit$hedges.g[2]*-1, fit$cohen.d[2]*-1),
           ci_lower = ifelse(hedges_correction, min(fit$hedges.g*-1), min(fit$cohen.d*-1)),
           ci_upper = ifelse(hedges_correction, max(fit$hedges.g*-1), max(fit$cohen.d*-1)))
  
  return(res)
}



cohens_d_s_mbess <- function(data, hedges_correction = TRUE){
  require(dplyr)
  require(MBESS)
  
  d <- MBESS::smd(Group.1 = data |> filter(timepoint == "post") |> pull(score), 
                  Group.2 = data |> filter(timepoint == "pre") |> pull(score),
                  Unbiased = hedges_correction)
  
  t <- t.test(score ~ timepoint, data = data)$statistic
  
  cis <- ci.smd(ncp = t,
                #smd = d, 
                n.1 = data |> filter(timepoint == "post") |> pull(score) |> length(), 
                n.2 = data |> filter(timepoint == "pre") |> pull(score) |> length())
  
  res <- 
    data.frame(estimate = cis$smd,
               ci_lower = cis$Lower.Conf.Limit.smd,
               ci_upper = cis$Upper.Conf.Limit.smd) 
  
  return(res)
}


cohens_d_s_lsr <- function(data){
  require(dplyr)
  require(tibble)
  require(lsr)
  
  # note that lsr::cohenD returns the absolute value of cohen's d, ie always positive values. fix this here to bring it in line with other packages' functions.
  mean_pre <- data |> dplyr::filter(timepoint == "pre") |> summarize(mean = mean(score))
  mean_post <- data |> dplyr::filter(timepoint == "post") |> summarize(mean = mean(score))
  
  d <- lsr::cohensD(score ~ timepoint,
                    data = data) 
  
  res <- 
    tibble(estimate = as.numeric(ifelse(mean_pre < mean_post, d, d * -1)),
           ci_lower = NA,
           ci_upper = NA) 
  
  return(res)
}


cohens_d_dep_lsr <- function(data){
  require(dplyr)
  require(tibble)
  require(lsr)
  
  # note that lsr::cohenD returns the absolute value of cohen's d, ie always positive values. fix this here to bring it in line with other packages' functions.
  mean_pre <- data |> dplyr::filter(timepoint == "pre") |> summarize(mean = mean(score))
  mean_post <- data |> dplyr::filter(timepoint == "post") |> summarize(mean = mean(score))
  
  d <- lsr::cohensD(data |> dplyr::filter(timepoint == "pre") |> pull(score),
                    data |> dplyr::filter(timepoint == "post") |> pull(score),
                    method = "paired") 
  
  res <- 
    tibble(estimate = as.numeric(ifelse(mean_pre < mean_post, d, d * -1)),
           ci_lower = NA,
           ci_upper = NA) 
  
  return(res)
}


# # assumes that 'data' contains columns named score (numeric) and timepoint (factor with two levels, pre and post, where positive cohen's d means higher scores at post)
# # assumes a two sided Student's t test with alpha = .05
# # by default, assumes correlation between timepoints is 0. larger values will narrow the CIs but leave the estimate unchanged. so, default result is the worst case precision.
# d_t_dependent <- function(data, hedges_correction = TRUE, r = 0) { # assumes a correlation of 0 for simplicity
#   require(dplyr)
#   
#   fit <- t.test(data$score[data$timepoint == "post"],
#                 data$score[data$timepoint == "pre"], 
#                 paired = TRUE)
#   
#   res <- 
#     data.frame(t_stat = fit$statistic["t"],
#                df = fit$parameter["df"],
#                r = r) |>
#     mutate(n = df + 1, # for dependent t test, n = df + 1
#            dt_estimate = t_stat / sqrt(n), # for dependent t test, d_t = t / sqrt(n)
#            dt_estimate = ifelse(hedges_correction, 
#                                 dt_estimate * (1 - (3 / (4 * n - 9))),
#                                 dt_estimate),
#            dt_se = sqrt((2 * (1 - r)) / n + (dt_estimate ^ 2) / (2 * n)), # default assumes a correlation of 0
#            ci_lower = dt_estimate - (1.96 * dt_se),
#            ci_upper = dt_estimate + (1.96 * dt_se),
#            hedges_correction = hedges_correction) |>
#     dplyr::select(hedges_correction, estimate = dt_estimate, ci_lower, ci_upper)
#   
#   return(res)
# }


# # cohen's d from a Student's t test (two sided, alpha = .05)
# # if a Welches' t test, the conversion of df to N is imprecise, affecting the CIs.
# # assumes that 'data' contains columns named score (numeric) and timepoint (factor with two levels)
# d_t_independent <- function(data, hedges_correction = TRUE){
#   require(dplyr)
#   
#   fit <- t.test(score ~ timepoint, 
#                 data = data,
#                 paired = FALSE, 
#                 var.equal = TRUE)
#   
#   res <- 
#     data.frame(t_stat = fit$statistic["t"],
#                df = fit$parameter["df"]) |>
#     mutate(n1 = data |> filter(timepoint == "post") |> nrow(),
#            n2 = data |> filter(timepoint == "pre") |> nrow(),
#            dt_estimate = t_stat * sqrt(1/n1 + 1/n2), # d = t * sqrt(1/n1 + 1/n2) - from lakens 2013 equation 2
#            dt_estimate = ifelse(hedges_correction, 
#                                 dt_estimate * (1 - (3 / (4 * n - 9))),
#                                 dt_estimate),
#            dt_se = sqrt((n1 + n2) / (n1 * n2) + (dt_estimate^2) / (2 * (n1 + n2 - 2))),
#            ci_lower = dt_estimate - (1.96 * dt_se),
#            ci_upper = dt_estimate + (1.96 * dt_se),
#            hedges_correction = hedges_correction) |>
#     dplyr::select(hedges_correction, estimate = dt_estimate, ci_lower, ci_upper)
#   
#   return(res)
# }


multiple_cohens_ds_for_dependent_data <- function(data, hedges_correction = TRUE){
  
  # Check if 'data' is a dataframe or tibble
  if (!is.data.frame(data) && !is_tibble(data)) {
    stop("The 'data' argument must be a dataframe or tibble.")
  }
  
  # Check for 'score' column and its type
  if (!"score" %in% names(data) || !is.numeric(data$score)) {
    stop("The 'data' must contain a numeric column named 'score'.")
  }
  
  # Check for 'timepoint' column, its type, and number of levels
  if (!"timepoint" %in% names(data)) {
    stop("The 'data' must contain a column named 'timepoint'.")
  }
  if (!is.factor(data$timepoint) && !is.character(data$timepoint)) {
    stop("The 'timepoint' column must be of type factor or character.")
  }
  
  # some pivots below assume only these columns are present
  data <- data |>
    select(id, timepoint, score)
  
  # Convert 'timepoint' to factor if it's not already
  data$timepoint <- as.factor(data$timepoint)
  
  # Check that 'timepoint' has exactly two levels
  if (nlevels(data$timepoint) != 2) {
    stop("The 'timepoint' column must have exactly two levels.")
  }
  
  results <- 
    bind_rows(
      effectsize::cohens_d(score ~ timepoint, data = data, pooled_sd = TRUE, adjust = hedges_correction) |> 
        as_tibble() |> 
        mutate(type = "d_s",
               implementation = "{effectsize}",
               hedges_correction = hedges_correction) |>
        dplyr::select(implementation, type, hedges_correction, estimate = Hedges_g, ci_lower = CI_low, ci_upper = CI_high),
      
      cohens_d_s_psych(data = data, hedges_correction = hedges_correction) |> 
        as_tibble() |> 
        mutate(type = "d_s",
               implementation = "{psych}",
               hedges_correction = hedges_correction) |>
        dplyr::select(implementation, type, hedges_correction, estimate, ci_lower, ci_upper),
      
      cohens_d_s_mbess(data = data, hedges_correction = hedges_correction) |> 
        mutate(type = "d_s",
               implementation = "{MBESS}",
               hedges_correction = hedges_correction) |>
        dplyr::select(implementation, type, hedges_correction, estimate, ci_lower, ci_upper),
      
      cohens_d_s_effsize(data = data, hedges_correction = hedges_correction) |> 
        mutate(type = "d_s",
               implementation = "{effsize}",
               hedges_correction = hedges_correction) |>
        dplyr::select(implementation, type, hedges_correction, estimate, ci_lower, ci_upper),
      
      # cohens_d_s_rstatix(data = data, hedges_correction = hedges_correction) |> 
      #   mutate(type = "d_s",
      #          implementation = "{rstatix}",
      #          hedges_correction = hedges_correction) |>
      #   dplyr::select(implementation, type, hedges_correction, estimate, ci_lower, ci_upper),
      
      cohens_d_s_metafor(data = data) |> 
        mutate(type = "d_s",
               implementation = "{metafor}",
               hedges_correction = TRUE) |> # nb always applies hedges correction
        dplyr::select(implementation, type, hedges_correction, estimate, ci_lower, ci_upper),
      
      # cohens_d_z_rstatix(data = data, hedges_correction = hedges_correction) |> 
      #   mutate(type = "d_z",
      #          implementation = "{rstatix}",
      #          hedges_correction = hedges_correction) |>
      #   dplyr::select(implementation, type, hedges_correction, estimate, ci_lower, ci_upper),
      
      cohens_d_s_esc(data = data, hedges_correction = hedges_correction) |> 
        mutate(type = "d_s",
               implementation = "{esc}",
               hedges_correction = hedges_correction) |>
        dplyr::select(implementation, type, hedges_correction, estimate, ci_lower, ci_upper),
      
      cohens_d_z_esc(data = data, hedges_correction = hedges_correction) |> 
        mutate(type = "d_??? (dep)",
               implementation = "{esc}",
               hedges_correction = hedges_correction) |>
        dplyr::select(implementation, type, hedges_correction, estimate, ci_lower, ci_upper),
      
      cohens_d_s_esci(data = data, hedges_correction = hedges_correction) |> 
        mutate(type = "d_??? (indep)",
               implementation = "{esci}",
               hedges_correction = hedges_correction) |>
        dplyr::select(implementation, type, hedges_correction, estimate, ci_lower, ci_upper),
      
      cohens_d_dep_effsize(data = data, hedges_correction = hedges_correction) |> 
        mutate(type = "d_??? (dep)",
               implementation = "{effsize}",
               hedges_correction = hedges_correction) |>
        dplyr::select(implementation, type, hedges_correction, estimate, ci_lower, ci_upper),
      
      cohens_d_s_lsr(data = data) |> 
        mutate(type = "d_s",
               implementation = "{lsr}",
               hedges_correction = FALSE) |> # lsr doesn't have an option for hedges corrections
        dplyr::select(implementation, type, hedges_correction, estimate, ci_lower, ci_upper),
      
      cohens_d_dep_lsr(data = data) |> 
        mutate(type = "d_z",
               implementation = "{lsr}",
               hedges_correction = FALSE) |> # lsr doesn't have an option for hedges corrections
        dplyr::select(implementation, type, hedges_correction, estimate, ci_lower, ci_upper),
      
      # this provides nearly identical results to d_s under most conditions
      # effectsize::cohens_d(score ~ timepoint, data = data, pooled_sd = FALSE, adjust = hedges_correction) |>
      #   as_tibble() |>
      #   mutate(type = "d_s_nonpooled",
      #          implementation = "{effectsize}",
      #          hedges_correction = hedges_correction) |>
      #   dplyr::select(implementation, type, hedges_correction, estimate = Hedges_g, ci_lower = CI_low, ci_upper = CI_high),
      
      effectsize::repeated_measures_d(score ~ timepoint | id, data = data, method = "d", adjust = hedges_correction) |> 
        as_tibble() |> 
        mutate(type = "d_s_withinCIs",
               implementation = "{effectsize}",
               hedges_correction = hedges_correction) |>
        dplyr::select(implementation, type, hedges_correction, estimate = Cohens_d, ci_lower = CI_low, ci_upper = CI_high),
      
      effectsize::repeated_measures_d(score ~ timepoint | id, data = data, method = "rm", adjust = hedges_correction) |> 
        as_tibble() |> 
        mutate(type = "d_rm",
               implementation = "{effectsize}",
               hedges_correction = hedges_correction) |>
        dplyr::select(implementation, type, hedges_correction, estimate = d_rm, ci_lower = CI_low, ci_upper = CI_high),
      
      effectsize::repeated_measures_d(score ~ timepoint | id, data = data, method = "av", adjust = hedges_correction) |> 
        as_tibble() |> 
        mutate(type = "d_av",
               implementation = "{effectsize}",
               hedges_correction = hedges_correction) |>
        dplyr::select(implementation, type, hedges_correction, estimate = d_av, ci_lower = CI_low, ci_upper = CI_high),
      
      effectsize::repeated_measures_d(score ~ timepoint | id, data = data, method = "b", adjust = hedges_correction) |> 
        as_tibble() |> 
        mutate(type = "d_b",
               implementation = "{effectsize}",
               hedges_correction = hedges_correction) |>
        dplyr::select(implementation, type, hedges_correction, estimate = Beckers_d, ci_lower = CI_low, ci_upper = CI_high),
      
      # use timepoint post's SD rather than pre. 
      # this is useful to include as not all comparisons are pre-post, some are the same participants rating stimulus X and Y, and either could be the reference
      data |>
        mutate(timepoint = fct_relevel(timepoint, "pre", "post")) |>
        effectsize::repeated_measures_d(score ~ timepoint | id, data = _, method = "b", adjust = hedges_correction) |> 
        as_tibble() |> 
        mutate(type = "d_b (alt)",
               implementation = "{effectsize}",
               hedges_correction = hedges_correction,
               estimate = Beckers_d * -1,
               ci_lower = CI_high * -1,
               ci_upper = CI_low * -1) |>
        dplyr::select(implementation, type, hedges_correction, estimate, ci_lower, ci_upper),
      
      effectsize::repeated_measures_d(score ~ timepoint | id, data = data, method = "z", adjust = hedges_correction) |> 
        as_tibble() |> 
        mutate(type = "d_z",
               implementation = "{effectsize}",
               hedges_correction = hedges_correction) |>
        dplyr::select(implementation, type, hedges_correction, estimate = d_z, ci_lower = CI_low, ci_upper = CI_high)
      
      # # this provides the same estimate as d_s
      # d_t_independent(data = data, hedges_correction = hedges_correction) |>
      #   as_tibble() |>
      #   mutate(type = "d_t (independent)",
      #          implementation = "[custom]",
      #          hedges_correction = hedges_correction) |>
      #   dplyr::select(implementation, type, hedges_correction, estimate, ci_lower, ci_upper),
      # 
      # # this provides the same estimate as d_z with slightly wider CIs
      # d_t_dependent(data = data, hedges_correction = hedges_correction) |>
      #   as_tibble() |>
      #   mutate(type = "d_t (dependent, r = 0)",
      #          implementation = "[custom]",
      #          hedges_correction = hedges_correction) |>
      #   dplyr::select(implementation, type, hedges_correction, estimate, ci_lower, ci_upper)
    )
  return(results)
}

```

# Analyse

```{r}

if(!file.exists("models/results_aiid.rds")){
  
  # takes a few minutes to run on an M2 mac
  results <- dat_for_versions |>
    group_by(domain) |>
    nest() |>
    mutate(results = map(data, multiple_cohens_ds_for_dependent_data))
  
  dir.create("models")
  write_rds(results, "models/results_aiid.rds")

} else {
  
  results <- read_rds("models/results_aiid.rds")
  
}


summary <- dat_for_versions |>
  pivot_wider(names_from = "timepoint",
              values_from = "score") |>
  group_by(domain) |>
  summarize(r = cor(pre, post, method = "pearson"),
            n = n(),
            mean_x = mean(pre),
            mean_y = mean(post),
            sd_x = sd(pre),
            sd_y = sd(post),
            .groups = 'drop') |>
  ungroup() |>
  mutate(r_abs = abs(r))

results_unnested <- results |>
  ungroup() |>
  unnest(results) |>
  select(-data) |>
  left_join(summary, by = "domain") |>
  mutate(ci_width = ci_upper - ci_lower,
         sig = ifelse((ci_lower > 0 & ci_upper > 0) |
                        (ci_lower < 0 & ci_upper < 0) |
                        (is.na(ci_lower) & is.na(ci_upper)), TRUE, FALSE))


```

# Subsets of results

## Most extreme correlation

Prolife - Prochoice: r = .75

```{r}

summary_current <- summary |>
  filter(domain == "Prolife - Prochoice") |>
  select(n, r, mean_x, mean_y, sd_x, sd_y) |>
  mutate_if(is.numeric, janitor::round_half_up, digits = 2)

summary_current |>
  pivot_longer(cols = everything()) |>
  knitr::kable() 

p_prolife_prochoice <- results_unnested |>
  filter(domain == "Prolife - Prochoice") |>
  ggplot(aes(paste(type, implementation), estimate, color = sig)) + 
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper), size = 0.8) +
  geom_point(position = position_dodge(width = 0.5), size = 1.8) +
  scale_y_continuous(breaks = seq(-2, 2, 0.1)) +
  coord_flip() +
  theme_linedraw() +
  xlab("") +
  ylab("Cohen's d") +
  scale_color_viridis_d(begin = 0.2, end = 0.5, option = "D") +
  theme(legend.position = "none",
        panel.grid.minor = element_blank()) +
  ggtitle(paste0("Most extreme correlation: Prolife - Prochoice\n(n = ", summary_current$n, 
                 ", m1 = ", round_half_up_min_decimals(summary_current$mean_x, 1), 
                 ", m2 = ", round_half_up_min_decimals(summary_current$mean_y, 1), 
                 ", sd1 = ", round_half_up_min_decimals(summary_current$sd_x, 1), 
                 ", sd2 = ", round_half_up_min_decimals(summary_current$sd_y, 1), 
                 ", r = ", round_half_up_min_decimals(summary_current$r, 1), 
                 ")"))

p_prolife_prochoice

ggsave(filename = "p_prolife_prochoice.png",
       plot = p_prolife_prochoice,
       path = "../plots/",
       device = "png",
       width = 7,
       height = 4)

```

## Correlation close to zero

Dogs - Cats: r = -.01

```{r}

summary_current <- summary |>
  filter(domain == "Dogs - Cats") |>
  select(n, r, mean_x, mean_y, sd_x, sd_y) |>
  mutate_if(is.numeric, janitor::round_half_up, digits = 2)

summary_current |>
  pivot_longer(cols = everything()) |>
  knitr::kable() 

p_dogs_cats <- results_unnested |>
  filter(domain == "Dogs - Cats") |>
  ggplot(aes(paste(type, implementation), estimate, color = sig)) + 
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper), size = 0.8) +
  geom_point(position = position_dodge(width = 0.5), size = 1.8) +
  scale_y_continuous(breaks = seq(-2, 2, 0.1)) +
  coord_flip() +
  theme_linedraw() +
  xlab("") +
  ylab("Cohen's d") +
  scale_color_viridis_d(begin = 0.2, end = 0.5, option = "D") +
  theme(legend.position = "none",
        panel.grid.minor = element_blank()) +
  ggtitle(paste0("Correlation close to 0: Dogs - Cats\n(n = ", summary_current$n, 
                 ", m1 = ", round_half_up_min_decimals(summary_current$mean_x, 1), 
                 ", m2 = ", round_half_up_min_decimals(summary_current$mean_y, 1), 
                 ", sd1 = ", round_half_up_min_decimals(summary_current$sd_x, 1), 
                 ", sd2 = ", round_half_up_min_decimals(summary_current$sd_y, 1), 
                 ", r = ", round_half_up_min_decimals(summary_current$r, 1), 
                 ")"))

p_dogs_cats

ggsave(filename = "p_dogs_cats.png",
       plot = p_dogs_cats,
       path = "../plots/",
       device = "png",
       width = 7,
       height = 4)

```

## Mean correlation

Mean absolute correlation = .27
Foreign Places - American Places: r = .27

```{r}

# summary |>
#   summarize(mean_r_abs = mean(r_abs))

summary_current <- summary |>
  filter(domain == "Foreign Places - American Places") |>
  select(n, r, mean_x, mean_y, sd_x, sd_y) |>
  mutate_if(is.numeric, janitor::round_half_up, digits = 2)

summary_current |>
  pivot_longer(cols = everything()) |>
  knitr::kable() 

p_american_foreign <- results_unnested |>
  filter(domain == "Foreign Places - American Places") |>
  ggplot(aes(paste(type, implementation), estimate, color = sig)) + 
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper), size = 0.8) +
  geom_point(position = position_dodge(width = 0.5), size = 1.8) +
  scale_y_continuous(breaks = seq(-10, 10, 0.1)) +
  coord_flip() +
  theme_linedraw() +
  xlab("") +
  ylab("Cohen's d") +
  scale_color_viridis_d(begin = 0.2, end = 0.5, option = "D") +
  theme(legend.position = "none",
        panel.grid.minor = element_blank()) +
  ggtitle(paste0("Average correlation: Foreign Places - American Places\n(n = ", summary_current$n, 
                 ", m1 = ", round_half_up_min_decimals(summary_current$mean_x, 1), 
                 ", m2 = ", round_half_up_min_decimals(summary_current$mean_y, 1), 
                 ", sd1 = ", round_half_up_min_decimals(summary_current$sd_x, 1), 
                 ", sd2 = ", round_half_up_min_decimals(summary_current$sd_y, 1), 
                 ", r = ", round_half_up_min_decimals(summary_current$r, 1), 
                 ")"))

p_american_foreign

ggsave(filename = "p_p_american_foreign.png",
       plot = p_american_foreign,
       path = "../plots/",
       device = "png",
       width = 7,
       height = 4)

```

## Most extreme difference in means

Determinism - Free will: abs(mean_x - mean_y) = 3.80

```{r}

# summary |>
#   rowwise() |>
#   mutate(abs_diff = abs(mean_x - mean_y)) |>
#   arrange(desc(abs_diff))

summary_current <- summary |>
  filter(domain == "Determinism - Free will") |>
  select(n, r, mean_x, mean_y, sd_x, sd_y) |>
  mutate_if(is.numeric, janitor::round_half_up, digits = 2)

summary_current |>
  pivot_longer(cols = everything()) |>
  knitr::kable() 

p_determinism_freewill <- results_unnested |>
  filter(domain == "Determinism - Free will") |>
  ggplot(aes(paste(type, implementation), estimate, color = sig)) + 
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper), size = 0.8) +
  geom_point(position = position_dodge(width = 0.5), size = 1.8) +
  scale_y_continuous(breaks = seq(-3, 3, 0.25)) +
  coord_flip() +
  theme_linedraw() +
  xlab("") +
  ylab("Cohen's d") +
  scale_color_viridis_d(begin = 0.2, end = 0.5, option = "D") +
  theme(legend.position = "none",
        panel.grid.minor = element_blank()) +
  ggtitle(paste0("Largest difference in means: Determinism - Free will\n(n = ", summary_current$n, 
                 ", m1 = ", round_half_up_min_decimals(summary_current$mean_x, 1), 
                 ", m2 = ", round_half_up_min_decimals(summary_current$mean_y, 1), 
                 ", sd1 = ", round_half_up_min_decimals(summary_current$sd_x, 1), 
                 ", sd2 = ", round_half_up_min_decimals(summary_current$sd_y, 1), 
                 ", r = ", round_half_up_min_decimals(summary_current$r, 1), 
                 ")"))

p_determinism_freewill

ggsave(filename = "p_determinism_freewill.png",
       plot = p_determinism_freewill,
       path = "../plots/",
       device = "png",
       width = 7,
       height = 4)

```

## Difference in means close to zero

Effort - Talent: abs(mean_x - mean_y) = .01

```{r}

# summary |>
#   rowwise() |>
#   mutate(abs_diff = abs(mean_x - mean_y)) |>
#   arrange(abs_diff)

summary_current <- summary |>
  filter(domain == "Effort - Talent") |>
  select(n, r, mean_x, mean_y, sd_x, sd_y) |>
  mutate_if(is.numeric, janitor::round_half_up, digits = 2)

summary_current |>
  pivot_longer(cols = everything()) |>
  knitr::kable() 

p_effort_talent <- results_unnested |>
  filter(domain == "Effort - Talent") |>
  ggplot(aes(paste(type, implementation), estimate, color = sig)) + 
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper), size = 0.8) +
  geom_point(position = position_dodge(width = 0.5), size = 1.8) +
  scale_y_continuous(breaks = seq(-2, 2, 0.05)) +
  coord_flip() +
  theme_linedraw() +
  xlab("") +
  ylab("Cohen's d") +
  scale_color_viridis_d(begin = 0.2, end = 0.5, option = "D") +
  theme(legend.position = "none",
        panel.grid.minor = element_blank()) +
  ggtitle(paste0("Near-zero difference in means: Determinism - Free will\n(n = ", summary_current$n, 
                 ", m1 = ", round_half_up_min_decimals(summary_current$mean_x, 1), 
                 ", m2 = ", round_half_up_min_decimals(summary_current$mean_y, 1), 
                 ", sd1 = ", round_half_up_min_decimals(summary_current$sd_x, 1), 
                 ", sd2 = ", round_half_up_min_decimals(summary_current$sd_y, 1), 
                 ", r = ", round_half_up_min_decimals(summary_current$r, 1), 
                 ")"))

p_effort_talent

ggsave(filename = "p_effort_talent.png",
       plot = p_effort_talent,
       path = "../plots/",
       device = "png",
       width = 7,
       height = 4)

```

## Smallest average SD

Manufactured - Natural: mean(c(sd_x, sd_y)) = 1.78

```{r}

# summary |>
#   rowwise() |>
#   mutate(average_sd = mean(c(sd_x, sd_y))) |>
#   arrange(average_sd)

summary_current <- summary |>
  filter(domain == "Manufactured - Natural") |>
  select(n, r, mean_x, mean_y, sd_x, sd_y) |>
  mutate_if(is.numeric, janitor::round_half_up, digits = 2)

summary_current |>
  pivot_longer(cols = everything()) |>
  knitr::kable() 

p_manufactured_natural <- results_unnested |>
  filter(domain == "Manufactured - Natural") |>
  ggplot(aes(paste(type, implementation), estimate, color = sig)) + 
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper), size = 0.8) +
  geom_point(position = position_dodge(width = 0.5), size = 1.8) +
  scale_y_continuous(breaks = seq(-2, 2, 0.1)) +
  coord_flip() +
  theme_linedraw() +
  xlab("") +
  ylab("Cohen's d") +
  scale_color_viridis_d(begin = 0.2, end = 0.5, option = "D") +
  theme(legend.position = "none",
        panel.grid.minor = element_blank()) +
  ggtitle(paste0("Smallest SDs: Manufactured - Natural\n(n = ", summary_current$n, 
                 ", m1 = ", round_half_up_min_decimals(summary_current$mean_x, 1), 
                 ", m2 = ", round_half_up_min_decimals(summary_current$mean_y, 1), 
                 ", sd1 = ", round_half_up_min_decimals(summary_current$sd_x, 1), 
                 ", sd2 = ", round_half_up_min_decimals(summary_current$sd_y, 1), 
                 ", r = ", round_half_up_min_decimals(summary_current$r, 1), 
                 ")"))

p_manufactured_natural

ggsave(filename = "p_manufactured_natural.png",
       plot = p_manufactured_natural,
       path = "../plots/",
       device = "png",
       width = 7,
       height = 4)

```

## Largest difference in SD

National Defense - Education: see below.

## Largest difference between estimates

National Defense - Education: max_estimate / min_estimate = 2.68

```{r}

# results_unnested |>
#   group_by(domain) |>
#   summarize(min_estimate = min(estimate),
#             max_estimate = max(estimate)) |>
#   mutate(diff_max_min = max_estimate - min_estimate,
#          proportion_max_min = max_estimate / min_estimate) |>
#   arrange(desc(proportion_max_min)) |>
#   mutate_if(is.numeric, janitor::round_half_up, digits = 2)

summary_current <- summary |>
  filter(domain == "National Defense - Education") |>
  select(n, r, mean_x, mean_y, sd_x, sd_y) |>
  mutate_if(is.numeric, janitor::round_half_up, digits = 2)

summary_current |>
  pivot_longer(cols = everything()) |>
  knitr::kable() 

p_nationaldefense_education <- results_unnested |>
  filter(domain == "National Defense - Education") |>
  ggplot(aes(paste(type, implementation), estimate, color = sig)) + 
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper), size = 0.8) +
  geom_point(position = position_dodge(width = 0.5), size = 1.8) +
  scale_y_continuous(breaks = seq(-2, 3, 0.2)) +
  coord_flip() +
  theme_linedraw() +
  xlab("") +
  ylab("Cohen's d") +
  scale_color_viridis_d(begin = 0.2, end = 0.5, option = "D") +
  theme(legend.position = "none",
        panel.grid.minor = element_blank()) +
  ggtitle(paste0("Largest disagreement between Cohen's d estimates:\nNational Defense - Education\n(n = ", summary_current$n, 
                 ", m1 = ", round_half_up_min_decimals(summary_current$mean_x, 1), 
                 ", m2 = ", round_half_up_min_decimals(summary_current$mean_y, 1), 
                 ", sd1 = ", round_half_up_min_decimals(summary_current$sd_x, 1), 
                 ", sd2 = ", round_half_up_min_decimals(summary_current$sd_y, 1), 
                 ", r = ", round_half_up_min_decimals(summary_current$r, 1), 
                 ")"))

p_nationaldefense_education

ggsave(filename = "p_nationaldefense_education.png",
       plot = p_nationaldefense_education,
       path = "../plots/",
       device = "png",
       width = 7,
       height = 4)

```

# Session info

```{r}

sessionInfo()

```

