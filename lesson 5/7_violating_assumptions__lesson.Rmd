---
title: "Assessing the impact of violating the assumption of normality"
subtitle: "Within a Welches' independent *t*-test"
author: "Ian Hussey"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    code_folding: show
    highlight: haddock
    theme: flatly
    toc: yes
    toc_float: yes
---

# Overview of tutorial

We are frequently told that statistical tests have assumptions, that it is important to check these assumptions, and that there are consequences for violating them. What consequences, specifically? How badly do they need to be violated to substantively affect our inferences? In a previous lesson we examined how robust Welches' *t*-test vs. Students' *t*test is to differences in variances between the conditions. In this lesson, we will examine how violating the assumption of normality impacts the results of the Welches' *t*-test.

# Skew-normal distributions

In order to violate normality, we will need to use a different non-normal distribution. For this example we'll use the skew-normal distribution. Where the normal distribution of defined by two parameters, mean and standard deviation, other distributions are controlled by other parameters with different naming conventions, and often more than two parameters. 

The skew-normal distribution is defined by:

- 'location', akin to mean, controlled via parameter 'xi' in `sn()`. In fact, mean is referred to as 'location' in many distributions.
- 'scale', akin to SD, controlled via parameter 'omega' in `sn()`. Likewise, 'scale' is a common way of referring to measures of dispersion like SD.
- 'slant'/'skew', controlled via parameter 'alpha' in `sn()`.

Note that when alpha = 0, skew-normal data is the same as normal data:

```{r}

# dependencies
library(tidyr)
library(dplyr)
library(purrr) 
library(ggplot2)
library(sn)
library(knitr)
library(kableExtra)
library(janitor)

# simple plot of a normal distribution
set.seed(42)

rnorm(n = 100000, 
      mean = 0, 
      sd = 1) |>
  hist(main = "Normal data", xlab = "Score")

# simple plot of a skew-normal distribution
set.seed(42)

rsn(n = 100000, 
    xi = 0, 
    omega = 1, 
    alpha = 0) |>
  hist(main = "Skew-normal data when alpha = 0", xlab = "Score")

```

For more extreme values of alpha data becomes increasingly skewed. e.g., alpha = 12. 

```{r}

rsn(n = 100000, 
    xi = 0, 
    omega = 1, 
    alpha = 12) |>
  hist(main = "Skew-normal data when alpha is large (12)", xlab = "Score")

```

# Impact of non-normality on *p* value false-positive rates

## Data generation and analysis functions

```{r fig.height=5, fig.width=10}

# define data generating function ----
generate_data <- function(n_control,
                          n_intervention,
                          location_control, # location, akin to mean
                          location_intervention,
                          scale_control, # scale, akin to SD
                          scale_intervention,
                          skew_control, # slant/skew. When 0, produces normal/gaussian data
                          skew_intervention) {
  
  data_control <- 
    tibble(condition = "control",
           score = rsn(n = n_control, 
                       xi = location_control, # location, akin to mean
                       omega = scale_control, # scale, akin to SD
                       alpha = skew_control)) # slant/skew. When 0, produces normal/gaussian data
  
  data_intervention <- 
    tibble(condition = "intervention",
           score = rsn(n = n_intervention, 
                       xi = location_intervention, # location, akin to mean
                       omega = scale_intervention, # scale, akin to SD
                       alpha = skew_intervention)) # slant/skew. When 0, produces normal/gaussian data
  
  data <- bind_rows(data_control,
                    data_intervention) 
  
  return(data)
}


# define data analysis function ----
analyse_data <- function(data) {
  res_t_test <- t.test(formula = score ~ condition, 
                       data = data,
                       var.equal = FALSE,
                       alternative = "two.sided")
  
  res <- tibble(p = res_t_test$p.value)
  
  return(res)
}

```

## Between condition A: normal data

```{r}

# reminder of the distribution used in the simulation
rsn(n = 100000, 
    xi = 0, 
    omega = 1, 
    alpha = 0) |>
  hist(main = "Skew-normal data when alpha = 0", xlab = "Score")

# set the seed ----
# for the pseudo random number generator to make results reproducible
set.seed(42)

# define experiment parameters ----
experiment_parameters_grid_a <- expand_grid(
  n_control = 100,
  n_intervention = 100,
  location_control = 0,
  location_intervention = 0, 
  scale_control = 1,
  scale_intervention = 1,
  skew_control = 0,
  skew_intervention = 0, 
  iteration = 1:10000 
)

# run simulation ----
simulation_a <- 
  # using the experiment parameters
  experiment_parameters_grid_a |>
  
  # generate data using the data generating function and the parameters relevant to data generation
  mutate(generated_data = pmap(list(n_control,
                                    n_intervention,
                                    location_control,
                                    location_intervention,
                                    scale_control,
                                    scale_intervention,
                                    skew_control,
                                    skew_intervention),
                               generate_data)) |>
  
  # apply the analysis function to the generated data using the parameters relevant to analysis
  mutate(analysis_results = pmap(list(generated_data),
                                 analyse_data))
  

# summarise simulation results over the iterations ----
simulation_a_summary <- simulation_a |>
  unnest(analysis_results) |>
  group_by(location_intervention) |>
  summarize(false_positive_rate = janitor::round_half_up(mean(p < .05), digits = 3)) |>
  mutate(population_distribution = "normal")

```

## Between condition B: highly skewed data

```{r}

# reminder of the distribution used in the simulation
rsn(n = 100000, 
    xi = 0, 
    omega = 1, 
    alpha = 12) |>
  hist(main = "Skew-normal data when alpha = 12", xlab = "Score")

# set the seed ----
# for the pseudo random number generator to make results reproducible
set.seed(42)

# define experiment parameters ----
experiment_parameters_grid_b <- expand_grid(
  n_control = 100,
  n_intervention = 100,
  location_control = 0,
  location_intervention = 0, 
  scale_control = 1,
  scale_intervention = 1,
  skew_control = 12, # data in both conditions is highly skewed
  skew_intervention = 12, # data in both conditions is highly skewed
  iteration = 1:10000 
)

# run simulation ----
simulation_b <- 
  # using the experiment parameters
  experiment_parameters_grid_b |>
  
  # generate data using the data generating function and the parameters relevant to data generation
  mutate(generated_data = pmap(list(n_control,
                                    n_intervention,
                                    location_control,
                                    location_intervention,
                                    scale_control,
                                    scale_intervention,
                                    skew_control,
                                    skew_intervention),
                               generate_data)) |>
  
  # apply the analysis function to the generated data using the parameters relevant to analysis
  mutate(analysis_results = pmap(list(generated_data),
                                 analyse_data))
  

# summarise simulation results over the iterations ----
simulation_b_summary <- simulation_b |>
  unnest(analysis_results) |>
  summarize(false_positive_rate = janitor::round_half_up(mean(p < .05), digits = 3)) |>
  mutate(population_distribution = "highly skewed non-normal")

```

## Summarize results

```{r}

bind_rows(
  simulation_a_summary,
  simulation_b_summary
) |>
  kable() |>
  kable_classic(full_width = FALSE)

```

# Impact of non-normality on estimates of mean differences 

## Modify the data analysis function

NB we reuse the data generation function from above.

```{r fig.height=5, fig.width=10}

# define data analysis function ----
analyse_data <- function(data) {
  res_t_test <- t.test(formula = score ~ condition, 
                       data = data,
                       var.equal = FALSE,
                       alternative = "two.sided")
  
  res <- tibble(p = res_t_test$p.value,
                mean_control = res_t_test$estimate[1],
                mean_intervention = res_t_test$estimate[2])
  
  return(res)
}

# dat <- simulation_c$generated_data[[1]]
# 
# t.test(formula = score ~ condition, 
#                        data = dat,
#                        var.equal = FALSE,
#                        alternative = "two.sided")

```

## Between condition A: normal data

Medium sized difference difference between the groups (difference in location = 0.5)

```{r}

# reminder of the distribution used in the simulation
rsn(n = 100000, 
    xi = 0, 
    omega = 1, 
    alpha = 0) |>
  hist(main = "Skew-normal data when alpha = 0", xlab = "Score")

# set the seed ----
# for the pseudo random number generator to make results reproducible
set.seed(42)

# define experiment parameters ----
experiment_parameters_grid_c <- expand_grid(
  n_control = 50,
  n_intervention = 50,
  location_control = 0,
  location_intervention = 0.5, # medium sized difference difference between the groups. proportion of p < .05 results therefore represents true positive rate.
  scale_control = 1,
  scale_intervention = 1,
  skew_control = 0,
  skew_intervention = 0, 
  iteration = 1:10000 
)

# run simulation ----
simulation_c <- 
  # using the experiment parameters
  experiment_parameters_grid_c |>
  
  # generate data using the data generating function and the parameters relevant to data generation
  mutate(generated_data = pmap(list(n_control,
                                    n_intervention,
                                    location_control,
                                    location_intervention,
                                    scale_control,
                                    scale_intervention,
                                    skew_control,
                                    skew_intervention),
                               generate_data)) |>
  
  # apply the analysis function to the generated data using the parameters relevant to analysis
  mutate(analysis_results = pmap(list(generated_data),
                                 analyse_data))
  

# summarise simulation results over the iterations ----
simulation_c_summary <- simulation_c |>
  unnest(analysis_results) |>
  summarize(sample_mean_control = mean(mean_control),
            sample_mean_intervention = mean(mean_intervention)) |>
  mutate(pop_distribution = "normal",
         pop_location_control = 0,
         pop_location_intervention = 0.5) 

```

## Between condition B: highly skewed data

Medium sized difference difference between the groups (difference in location = 0.5)

```{r}

# reminder of the distribution used in the simulation
rsn(n = 100000, 
    xi = 0, 
    omega = 1, 
    alpha = 12) |>
  hist(main = "Skew-normal data when alpha = 12", xlab = "Score")

# set the seed ----
# for the pseudo random number generator to make results reproducible
set.seed(42)

# define experiment parameters ----
experiment_parameters_grid_d <- expand_grid(
  n_control = 50,
  n_intervention = 50,
  location_control = 0,
  location_intervention = 0.5, # medium sized difference difference between the groups. proportion of p < .05 results therefore represents true positive rate.
  scale_control = 1,
  scale_intervention = 1,
  skew_control = 12, # data in both conditions is highly skewed
  skew_intervention = 12, # data in both conditions is highly skewed
  iteration = 1:10000 
)

# run simulation ----
simulation_d <- 
  # using the experiment parameters
  experiment_parameters_grid_d |>
  
  # generate data using the data generating function and the parameters relevant to data generation
  mutate(generated_data = pmap(list(n_control,
                                    n_intervention,
                                    location_control,
                                    location_intervention,
                                    scale_control,
                                    scale_intervention,
                                    skew_control,
                                    skew_intervention),
                               generate_data)) |>
  
  # apply the analysis function to the generated data using the parameters relevant to analysis
  mutate(analysis_results = pmap(list(generated_data),
                                 analyse_data))
  

# summarise simulation results over the iterations ----
simulation_d_summary <- simulation_d |>
  unnest(analysis_results) |>
  summarize(sample_mean_control = mean(mean_control),
            sample_mean_intervention = mean(mean_intervention)) |>
  mutate(pop_distribution = "non-normal",
         pop_location_control = 0,
         pop_location_intervention = 0.5) 

```

## Summarize results

```{r}

bind_rows(
  simulation_c_summary,
  simulation_d_summary
) |>
  relocate(pop_distribution, pop_location_control, sample_mean_control, pop_location_intervention, sample_mean_intervention) |>
  mutate(sample_diff = sample_mean_intervention - sample_mean_control) |>
  mutate_if(is.numeric, janitor::round_half_up, digits = 2) |>
  kable() |>
  kable_classic(full_width = FALSE)

```

- The sample means do match the population locations when the data is normal (i.e., skew normal when alpha = 0)
- The sample means do *not* match the population locations when the data is highly non-normal (i.e., highly skewed, alpha = 12)
- Nonetheless, the differences in sample means between the conditions *does* match the difference in population locations even when the data is highly non-normal.

# Wrapping up

Why don't the sample means match the population locations? Because mean and location are comparable but not the same thing. A simple demonstration using a large sample shows us this:

```{r}

rnorm(n = 1000000, 
      mean = 0.45, 
      sd = 1) |>
  mean() |>
  round_half_up(digits = 2)


rsn(n = 1000000, 
    xi = 0.45, # location, akin to mean but not equal to mean
    omega = 1, 
    alpha = 12) |>
  mean() |>
  round_half_up(digits = 2)

```

So, why do we care about assumptions not being violated, if it doesn't change either (a) the *p* value false positive rate or (b) the (unstandardized) estimate of effect size?

In class we will brainstorm answers to this question together.

# Session info

```{r}

sessionInfo()

```


