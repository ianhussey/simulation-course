---
title: "Practice writing R functions"
author: "Ian Hussey"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    code_folding: show
    highlight: haddock
    theme: flatly
    toc: yes
    toc_float: yes
---

Two of the key steps in a simulation study (generate data and analyze data) require us to know how to write functions. This R Markdown lesson practices this.

```{r, include=FALSE}

# set default chunk options
knitr::opts_chunk$set(message = FALSE,
                      warning = FALSE)

# disable scientific notation
options(scipen = 999) 

```

```{r}

# dependencies
library(dplyr)
library(tibble)
library(forcats)

```

# Primer on functions

Most code we use are functions, e.g., `mean()`, `setwd()` and `library()`.

These functions were written by others, but we can write our own. 

"It's functions all the down": you will use existing functions to write new ones. For example:

```{r}

values <- c(4, 2, 6, 2, NA, 4, 3, 1, NA, 7, 5)

mean(values) # returns NA 
mean(values, na.rm = TRUE) # returns the mean after dropping NA

# tired of writing 'na.rm = TRUE' repeatedly? write your own function to do it automatically
mean_na_rm <- function(x){
  mean(x, na.rm = TRUE)
}

mean_na_rm(values) # returns the mean after dropping NA

```

What if we usually want to `round()` to two decimal places, and we're tired of writing `digits = 2` every time?

```{r}

mean_of_values <- mean_na_rm(values)

round(mean_of_values, digits = 2)

# write a function to always round to two decimal places
round_2 <- function(x){
  round(x, digits = 2)
}

round_2(mean_of_values)

```

## Mini lesson: round() probably doesn't do what you think it does

round() uses "banker's rounding" rather than the round-half-up method we're used to

```{r}

round(0.5)
round(1.5)
round(2.5)
round(3.5)
round(4.5)
round(5.5)

```


```{r}

library(janitor)

round_half_up(0.5)
round_half_up(1.5)
round_half_up(2.5)
round_half_up(3.5)
round_half_up(4.5)
round_half_up(5.5)

```

## TODO add content on variable scoping inside functions

\TODO

## General structure of a function

Functions (usually) have 'inputs', they have code that they run ('do stuff'), and they (almost always) return 'outputs'. The often specify their requirements and include checks that their inputs are correctly formatted.

Note that this is pseudo-code only: chunk is set not to run (`eval=FALSE`).

```{r eval=FALSE}

# define function
function_name <- function(argument_1, # first argument is often the data, if the function takes a data frame as an argument
                          argument_2 = "default", # arguments can have defaults
                          argument_3) {
  # required packages
  require(dplyr)
  
  # checks
  # well written functions contain checks. 
  # e.g., if the function assumes that argument_1 is a data frame, check that this is the case.
  # note that it is more useful to write the function first and add checks later.
  if(!is.data.frame(argument_1)){
    stop("argument_1 must be a data frame")
  }
  
  # code that does things
  object_to_be_returned <- input_data_frame |>
    # do things
    mutate(value = value + 1)
  
  # object to be returned
  return(object_to_be_returned)
}

```

## Example function: return rule of thumb magnitude label for Cohen's d value

```{r}

# define function
interpret_cohens_d_custom <- function(cohens_d) {
  # checks
  if (!is.numeric(cohens_d)) {
    stop("The Cohen's d value must be numeric.")
  }
  
  # requirements
  require(dplyr)
  require(tibble)
  
  # do stuff
  result <- data.frame(d = abs(cohens_d)) |>
    mutate(interpretation = case_when(d < .2 ~ "very small",
                                      d >= .2 & d < .5 ~ "small",
                                      d >= .5 & d < .8 ~ "medium", 
                                      d >= .8 ~ "large")) |>
    pull(interpretation)
  
  # return result
  return(result)
}

# call function
# lets do this with lots of different inputs to make sure it gives us the result we expect
interpret_cohens_d_custom(0.1)
interpret_cohens_d_custom(0.2)
interpret_cohens_d_custom(0.5)
interpret_cohens_d_custom(0.8)
interpret_cohens_d_custom(0.99)
interpret_cohens_d_custom(-0.55)
#interpret_cohens_d_custom("should throw error with this input")

```

## TODO add content on how to develop a function

- always start with do stuff, only wrap with input and output when it works. why? so you don't have to fight variable scoping.
- always remember to swap out your inputs for variables or your code will run but produce the wrong results
- think about 

```{r}

# do stuff
  
cohens_d <- .47

my_func <- function(cohens_d){
  
  # cohens_d <- .47

  result <- data.frame(d = abs(cohens_d)) |>
    mutate(interpretation = case_when(d < .2 ~ "very small",
                                      d >= .2 & d < .5 ~ "small",
                                      d >= .5 & d < .8 ~ "medium", 
                                      d >= .8 ~ "large")) |>
    pull(interpretation)
  
  return(result)
}

```

## Remember:

- The function must be present in your environment to be usable, and must be called to be used
- Build the 'do stuff' part outside of a function first!
- If you can't immediately write the code, write pseudo-code first! 
- Check that your function actually works as you expect, not just that it runs. Give it lots of different input values that should and should not work, and check you get the correct outputs.
- don't try to abstract more than you need.

# Practice writing functions

## APA-style rounding of p values

Goal: Convert a *p* value's significance to create APA-format table stars (i.e., "\*\*\*" vs. "\*\*" vs. "\*" vs "ns")

```{r}

# convert a p value to sig stars
p_value_to_significance_stars <- function(p_value){
  
  # do stuff
  
  return(result)
}

p_value_to_significance_stars(.06)
p_value_to_significance_stars(.02)

```

## p value from correlation test

Goal: Fit a correlation test using cor.test() and extract the p value and correlation

```{r}

# use this data to build and test your function
data_simulated <- tibble(Y = rnorm(n = 100, mean = 0, sd = 1),
                         X = rnorm(n = 100, mean = 0, sd = 1))


cor_extraction <- function(data){
  
  res_cor <- cor.test(data$X, data$Y)
  
  res <- list(res_cor$p.value,
              res_cor$estimate)
  
  return(res)
}

res_a <- cor_extraction(data_simulated)
res_a[[1]]


cor_extraction <- function(data){
  
  res_cor <- cor.test(data$X, data$Y)
  
  res <- data.frame(p = res_cor$p.value,
                    r = res_cor$estimate)
  
  return(res)
}

cor_extraction(data_simulated)

```

## p value from a t-test

Goal: Fit an independent Student's t-test using `t.test(var.equal = TRUE)` and extract the p value. Return the results as a data frame with the p value in the column "p".

```{r}

# use this data to build and test your function
data_simulated_intervention <- tibble(condition = "intervention", 
                                      score = rnorm(n = 50, mean = 0, sd = 1))

data_simulated_control <- tibble(condition = "control", 
                                 score = rnorm(n = 50, mean = 0, sd = 1))

data_simulated <- 
  bind_rows(data_simulated_intervention,
            data_simulated_control)


tttest_p <- function(data){
  res_ttest <- t.test(score ~ condition,
                      data = data)
  
  res_p <- res_ttest$p.value
  
  res <- tibble(p = res_p)
  
  return(res)
}

tttest_p(data_simulated)

```

## Cohen's d and its confidence intervals 

Goal: Calculate cohen's d using effsize::cohen.d() and return the estimate and its p values as a data frame.

```{r}

# use this data to build and test your function
data_simulated_intervention <- tibble(condition = "intervention", 
                                      score = rnorm(n = 50, mean = 0, sd = 1))

data_simulated_control <- tibble(condition = "control", 
                                 score = rnorm(n = 50, mean = 0, sd = 1))

data_simulated <- 
  bind_rows(data_simulated_intervention,
            data_simulated_control) |>
  # control's factor levels must be ordered so that intervention is the first level and control is the second
  # this ensures that positive cohen's d values refer to intervention > control and not the other way around.
  mutate(condition = fct_relevel(condition, "intervention", "control"))



extract_d <- function(data){
  res_cohens_d <- effsize::cohen.d(score ~ condition,
                                   data = data)
  
  res <- tibble(cohens_d = res_cohens_d$estimate,
                cohens_d_ci_lower = res_cohens_d$conf.int[["lower"]],
                cohens_d_ci_upper = res_cohens_d$conf.int[["upper"]])
  
  return(res)
}

extract_d(data_simulated)


# library(broom)
# library(parameters) # easystats


```

## t-test's p value, Cohen's d and its confidence intervals

```{r}

# use this data to build and test your function
data_simulated_intervention <- tibble(condition = "intervention", 
                                      score = rnorm(n = 50, mean = 0, sd = 1))

data_simulated_control <- tibble(condition = "control", 
                                 score = rnorm(n = 50, mean = 0, sd = 1))

data_simulated <- 
  bind_rows(data_simulated_intervention,
            data_simulated_control) |>
  # control's factor levels must be ordered so that intervention is the first level and control is the second
  # this ensures that positive cohen's d values refer to intervention > control and not the other way around.
  mutate(condition = fct_relevel(condition, "intervention", "control"))



analyze_data <- function(data) {
  # dependencies
  require(effsize)
  require(tibble)
  
  res_t_test <- t.test(formula = score ~ condition, 
                       data = data,
                       var.equal = TRUE,
                       alternative = "two.sided")
  
  res_cohens_d <- effsize::cohen.d(formula = score ~ condition,  # new addition: also fit cohen's d
                                   within = FALSE,
                                   data = data)
  
  res <- tibble(p = res_t_test$p.value, 
                cohens_d = res_cohens_d$estimate,  # new addition: save cohen's d and its 95% CIs to the results tibble
                cohens_d_ci_lower = res_cohens_d$conf.int["lower"],
                cohens_d_ci_upper = res_cohens_d$conf.int["upper"])
  
  return(res)
}


```

## Generate data for a between groups design

Goal: rather than writing a data analysis function, this time write a data generation function. In the previous chunks we've used this code to generate a single data set with intervention and control conditions and simulated normally distributed data. Rewrite this as a function so that we can generate such a data set with one line of code using the new function `generate_data()`. Unlike your previous functions, this one has no inputs, i.e., you can write `function() <- `.

```{r}

# use this *code* to build your data generation function
data_simulated_intervention <- tibble(condition = "intervention", 
                                      score = rnorm(n = 50, mean = 0, sd = 1))

data_simulated_control <- tibble(condition = "control", 
                                 score = rnorm(n = 50, mean = 0, sd = 1))

data_simulated <- 
  bind_rows(data_simulated_intervention,
            data_simulated_control) |>
  # control's factor levels must be ordered so that intervention is the first level and control is the second
  # this ensures that positive cohen's d values refer to intervention > control and not the other way around.
  mutate(condition = fct_relevel(condition, "intervention", "control"))




generate_data <- function(){
  data_simulated_intervention <- tibble(condition = "intervention", 
                                        score = rnorm(n = 50, mean = 0, sd = 1))
  
  data_simulated_control <- tibble(condition = "control", 
                                   score = rnorm(n = 50, mean = 0, sd = 1))
  
  data_simulated <- 
    bind_rows(data_simulated_intervention,
              data_simulated_control) |>
    # control's factor levels must be ordered so that intervention is the first level and control is the second
    # this ensures that positive cohen's d values refer to intervention > control and not the other way around.
    mutate(condition = fct_relevel(condition, "intervention", "control"))
  
  return(data_simulated)
}

generate_data() |>
  analyze_data()

```

## Create a more flexible data generation function 

Goal: What if we want to generate data with a different number of participants per condition? We can make the value of `n` a variable rather than a hard-coded value and add this to functions inputs/arguments.

```{r}

generate_data <- function(n_per_group){
  data_simulated_intervention <- tibble(condition = "intervention", 
                                        score = rnorm(n = n_per_group, mean = 0, sd = 1))
  
  data_simulated_control <- tibble(condition = "control", 
                                   score = rnorm(n = n_per_group, mean = 0, sd = 1))
  
  data_simulated <- 
    bind_rows(data_simulated_intervention,
              data_simulated_control) |>
    # control's factor levels must be ordered so that intervention is the first level and control is the second
    # this ensures that positive cohen's d values refer to intervention > control and not the other way around.
    mutate(condition = fct_relevel(condition, "intervention", "control"))
  
  return(data_simulated)
}

bind_rows(
  generate_data(n_per_group = 50) |>
    analyze_data(),
  generate_data(n_per_group = 100) |>
    analyze_data(),
  generate_data(n_per_group = 150) |>
    analyze_data(),
  generate_data(n_per_group = 200) |>
    analyze_data(),
  generate_data(n_per_group = 250) |>
    analyze_data(),
) |>
  mutate(ci_width = cohens_d_ci_upper - cohens_d_ci_lower) |>
  select(ci_width)

```

## Create a more flexible data generation function 

Goal: Rewrite the data generation function to make it even more flexible: make all Ns, Ms, and SDs variables that are set by the inputs.

```{r}

generate_data <- function(n_intervention, n_control = NA, m_intervention = 0, m_control = 0, sd_intervention = 1, sd_control = 1){
  data_simulated_intervention <- tibble(condition = "intervention", 
                                        score = rnorm(n = n_intervention, mean = m_intervention, sd = sd_intervention))
  
  data_simulated_control <- tibble(condition = "control", 
                                   score = rnorm(n = n_control, mean = m_control, sd = sd_control))
  
  data_simulated <- 
    bind_rows(data_simulated_intervention,
              data_simulated_control) |>
    # control's factor levels must be ordered so that intervention is the first level and control is the second
    # this ensures that positive cohen's d values refer to intervention > control and not the other way around.
    mutate(condition = fct_relevel(condition, "intervention", "control"))
  
  return(data_simulated)
}

generate_data(n_intervention = 25, 
              n_control = 25, 
              m_intervention = .5)

```

# Notes

Although we have practiced writing custom functions to extract statistical results / model parameters, it is worth knowing that the easystats family of packages includes [{parameters}](https://easystats.github.io/parameters/) package, which does a very good job of extracting model parameters from a very wide range of models including base R functions, lavaan, psych, and other packages. If you want to extract values from a model, consider using {parameters} to do a lot of the work for you when writing your function.

This lesson does not cover documenting your functions well, organizing them into an R package to make them easy to load and include help menus, or writing unit tests them. These are all very worth doing. Look into the {roxygen} package.

# Session info

```{r}

sessionInfo()

```


